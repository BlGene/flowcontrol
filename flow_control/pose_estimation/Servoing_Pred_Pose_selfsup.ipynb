{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1209,
   "id": "b0ceed92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['demo_imgs', 'live_imgs', 'rewards.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# demos_dir = Path(\"/misc/student/nayaka/paper/flowcontrol/flow_control/demo/tmp_new/cnn_new/\")\n",
    "# demo_dir_jpg = Path(\"/misc/student/nayaka/paper/flowcontrol/flow_control/demo/train_sim/demo_imgs/\")\n",
    "# live_dir_jpg = Path(\"/misc/student/nayaka/paper/flowcontrol/flow_control/demo/train_sim/live_imgs/\")\n",
    "# rewards_fn = Path(\"/misc/student/nayaka/paper/flowcontrol/flow_control/demo/tmp_new/cnn_run/\")\n",
    "\n",
    "runs_dir = Path(\"/home/buechner/servoing/data/servo_predict/trapeze_sim/\")\n",
    "demo_dir_jpg = Path(\"/home/buechner/servoing/data/servo_predict/trapeze_sim/demo_imgs/\")\n",
    "live_dir_jpg = Path(\"/home/buechner/servoing/data/servo_predict/trapeze_sim/live_imgs/\")\n",
    "# rewards_fn = Path(\"/misc/student/nayaka/paper/flowcontrol/flow_control/demo/tmp_new/cnn_run/\")\n",
    "\n",
    "# with open(demos_dir/\"demo_parts_manual3.json\") as f_obj:\n",
    "#     demo_parts = json.load(f_obj)\n",
    "\n",
    "with open(runs_dir/\"rewards.json\") as f_obj:\n",
    "    rewards = json.load(f_obj)    \n",
    "\n",
    "# # the number in runs is the index of this list\n",
    "# demos_list = sorted(os.listdir(demos_dir))\n",
    "# print(demos_list)\n",
    "# print(len(demos_list)-1)\n",
    "\n",
    "# demo_idx_to_dir = dict(enumerate(demos_list[:-1]))\n",
    "# print(demo_idx_to_dir)\n",
    "runs = sorted(os.listdir(runs_dir))\n",
    "print(runs)\n",
    "\n",
    "# also filter these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "id": "62f71914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_image(demo_dir, frame_index, depth=False):\n",
    "    arr = np.load(os.path.join(demo_dir, f\"frame_{frame_index:06d}.npz\"))\n",
    "    rgb_gripper = arr[\"rgb_gripper\"]\n",
    "    return rgb_gripper\n",
    "\n",
    "def get_info(demo_dir, frame_index):\n",
    "    arr = np.load(os.path.join(demo_dir, f\"frame_{frame_index:06d}.npz\"), allow_pickle=True)\n",
    "    return arr[\"robot_state\"].item(), arr[\"info\"].item()\n",
    "\n",
    "def pos_orn_to_matrix(pos, orn):\n",
    "    mat = np.eye(4)\n",
    "    if len(orn) == 4:\n",
    "        mat[:3, :3] = R.from_quat(orn).as_matrix()\n",
    "    elif len(orn) == 3:\n",
    "        mat[:3, :3] = R.from_euler('xyz', orn).as_matrix()\n",
    "    mat[:3, 3] = pos\n",
    "    return mat\n",
    "\n",
    "def get_tcp_pose(demo_dir, frame_index):\n",
    "    arr = np.load(os.path.join(demo_dir, f\"frame_{frame_index:06d}.npz\"),allow_pickle=True)\n",
    "    state = arr[\"robot_state\"].item()\n",
    "    return pos_orn_to_matrix(state[\"tcp_pos\"], state[\"tcp_orn\"])\n",
    "\n",
    "def get_extr_cal(demo_dir):\n",
    "    camera_info = np.load(Path(demo_dir) / \"camera_info.npz\", allow_pickle=True)\n",
    "    extr = camera_info[\"gripper_extrinsic_calibration\"]\n",
    "    return extr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cb26bc",
   "metadata": {},
   "source": [
    "# Define Distance Functions\n",
    "\n",
    "$d(s_t, s_d) \\in \\mathbb{R}$\n",
    "\n",
    "1. `GT_pose`: Ground truth pose distance\n",
    "2. `VS`: Visual Similarity ~ hand crafted function ~ reprojection distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "id": "cbca297c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def get_cam2obj(demo_dir, frame_num):\n",
    "#     state, info = get_info(demo_dir, frame_num)\n",
    "#     pos, orn = info[\"0\"][\"position\"], info[\"0\"][\"orientation\"]\n",
    "#     t_tcp_cam = get_extr_cal(demo_dir)\n",
    "#     t_tcp_cam = np.eye(4)\n",
    "#     t_tcp_robot = get_tcp_pose(demo_dir, frame_num)\n",
    "#     trf = np.linalg.inv(t_tcp_robot @ t_tcp_cam) @ pos_orn_to_matrix(pos, orn)\n",
    "#     return trf\n",
    "\n",
    "\n",
    "# cam2obj_demo = {}\n",
    "# for k, v in demo_idx_to_dir.items():\n",
    "#     #print(v, [x[\"start\"] for x in demo_parts[str(k)]])\n",
    "#     for part_index, parts in enumerate(demo_parts[str(k)]):\n",
    "#         start = parts[\"start\"]\n",
    "#         trf = get_cam2obj(demos_dir/v, start)\n",
    "#         cam2obj_demo[(k, part_index)] = trf\n",
    "\n",
    "        \n",
    "# def get_scores_GP_pose(run_obs_fn, demo_index, part_num):\n",
    "#     # d(s_t, s_d) where \n",
    "#     # run_dir -> s_t\n",
    "#     # demo_index, part_num -> s_d\n",
    "#     trf = get_cam2obj(run_obs_fn, 0)\n",
    "#     trf2 = cam2obj_demo[(demo_index, part_num)]\n",
    "        \n",
    "#     diff = trf2 @ np.linalg.inv(trf)\n",
    "#     pos_diff = np.linalg.norm(diff[0:3,3])\n",
    "#     orn_diff = R.from_matrix(diff[:3,:3]).magnitude()\n",
    "#     return pos_diff, orn_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "id": "8647dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flow_control.servoing.module import ServoingModule\n",
    "# control_config = dict(mode=\"pointcloud-abs-rotz\", threshold=0.40)\n",
    "# random_demo_dir = demos_dir / demo_idx_to_dir[0]\n",
    "# servo_module = ServoingModule(random_demo_dir, control_config=control_config,\n",
    "#                               start_paused=False)\n",
    "\n",
    "# def get_mask(demo_dir, frame_index):\n",
    "#     arr = np.load(demo_dir / \"servo_mask.npz\")\n",
    "#     mask = arr[\"mask\"][frame_index] == arr[\"fg\"][frame_index]\n",
    "#     return mask\n",
    "\n",
    "\n",
    "# def similarity_from_reprojection(live_rgb, demo_rgb, demo_mask, return_images=False):\n",
    "#     # evaluate the similarity via flow reprojection error\n",
    "#     flow = servo_module.flow_module.step(demo_rgb, live_rgb)\n",
    "#     warped = servo_module.flow_module.warp_image(live_rgb / 255.0, flow)\n",
    "#     error = np.linalg.norm((warped - (demo_rgb / 255.0)), axis=2) * demo_mask\n",
    "#     error = error.sum() / demo_mask.sum()\n",
    "#     mean_flow = np.linalg.norm(flow[demo_mask],axis=1).mean()\n",
    "#     if return_images:\n",
    "#         return error, mean_flow, flow, warped\n",
    "#     return error, mean_flow\n",
    "\n",
    "\n",
    "# def get_scores_VS(run_obs_fn, demo_index, part_num):\n",
    "#     s_t_rgb = get_image(run_obs_fn, 0)\n",
    "    \n",
    "#     demo_part_frame = demo_parts[str(demo_index)][part_num][\"start\"]\n",
    "#     demo_dir = demos_dir / demo_idx_to_dir[demo_index]    \n",
    "#     s_g_rgb = get_image(demo_dir, demo_part_frame)\n",
    "#     s_g_mask = get_mask(demo_dir, demo_part_frame)\n",
    "#     return similarity_from_reprojection(s_t_rgb, s_g_rgb, s_g_mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "id": "e9921708",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 139.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "from flow_control.graph.utils import ParamLib, get_keyframe_info, get_len, get_image, get_depth, get_pose, get_demonstrations, chunks\n",
    "from flow_control.graph.gnn import DisjGNN\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "def init_model(params):\n",
    "    model = DisjGNN(params)\n",
    "    state_dict = torch.load(os.path.join(params.paths.checkpoints, params.eval.inf_checkpoint),\n",
    "                            map_location=torch.device(params.model.device)\n",
    "                            )\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.to(params.model.device)\n",
    "\n",
    "    weights = [w for w in model.parameters() if w.requires_grad]\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_scores_cnn_sim(live_img, demo_img, model):\n",
    "\n",
    "    live_img = ToTensor()(live_img).view(-1, 3, 256, 256)\n",
    "    demo_img = ToTensor()(demo_img).view(-1, 3, 256, 256)\n",
    "\n",
    "    x = torch.cat([live_img, demo_img], dim=0).to(\"cuda\")\n",
    "    edge_index = torch.tensor([[0, 1]], dtype=torch.long).reshape(2, -1).to(\"cuda\")\n",
    "    out_x = model.img_encoder.forward(x)\n",
    "\n",
    "    # Construct edge features and concatenate\n",
    "    x_out_i, x_out_j = out_x[edge_index[0,:]].reshape(-1), out_x[edge_index[1,:]].reshape(-1)\n",
    "    cos_sim = torch.sigmoid(torch.nn.CosineSimilarity(dim=0)(x_out_i, x_out_j)).item()\n",
    "    # print(cos_sim)\n",
    "    # if cos_sim < 0.7:\n",
    "    #     cos_sim = cos_sim + 0.4\n",
    "    # elif cos_sim < 0.5:\n",
    "    #     cos_sim = cos_sim - 0.1\n",
    "    return np.clip(cos_sim, 0, 1) # cos_sim \n",
    "\n",
    "distance = \"cnn_sim\"\n",
    "config = \"/home/buechner/servoing/flowcontrol/flow_control/graph/params_fine.yaml\"\n",
    "\n",
    "params = ParamLib(config)\n",
    "\n",
    "model = init_model(params)\n",
    "\n",
    "scores_list = []\n",
    "rew_list = []\n",
    "runs = [i for i in range(500)]\n",
    "for run in tqdm(runs[:500]):\n",
    "    # print(run, runs_dir)\n",
    "    # parts = sorted(os.listdir(runs_dir / run))\n",
    "    parts = [\"p2\",]\n",
    "    # print(parts)\n",
    "    for part in parts:\n",
    "        # part_dir = runs_dir / run / part\n",
    "        # entrys = os.listdir(part_dir)\n",
    "        # assert len(entrys) == 1\n",
    "        # part_str = entrys[0]\n",
    "        # live_seed, demo_index = [int(x) for x in part_str.split(\"_\")]\n",
    "        # part_num = int(part.replace(\"p\",\"\"))\n",
    "        #print(part_dir, demo_index,\"x\",part_num, run)\n",
    "        \n",
    "        # load jpg live and demo image\n",
    "        jpg_demo_image = demo_dir_jpg / \"{0:06d}_{1}.jpg\".format(run, part)\n",
    "        demo_img_jpg = Image.open(jpg_demo_image)\n",
    "        live_img_jpg = Image.open(live_dir_jpg / \"{0:06d}_{1}.jpg\".format(run, part))\n",
    "        \n",
    "        # load demo frame\n",
    "        #demo_part_frame = demo_parts[str(demo_index)][part_num][\"start\"]\n",
    "        #demo_dir = demos_dir / demo_idx_to_dir[demo_index]\n",
    "        #demo_frame_fn = demos_dir / demo_idx_to_dir[demo_index] / \"frame_{0:06d}.npz\".format(demo_part_frame)\n",
    "        #demo_img_run = get_image(demo_dir, demo_part_frame)\n",
    "        \n",
    "        # if distance == \"GP_pose\":\n",
    "        #     scores = get_scores_GP_pose(part_dir/part_str, demo_index, part_num)\n",
    "        # elif distance == \"VS\":\n",
    "        #     scores = get_scores_VS(part_dir/part_str, demo_index, part_num)\n",
    "        # elif distance == \"cnn_sim\":\n",
    "        scores = get_scores_cnn_sim(live_img_jpg, demo_img_jpg, model)\n",
    "        # else:\n",
    "        #     raise ValueError\n",
    "        \n",
    "        scores_list.append(scores)\n",
    "        rew_list.append(rewards[\"{0:06d}\".format(run)])\n",
    "        \n",
    "        # plot\n",
    "        # fig, ax = plt.subplots(1, 2, figsize=(8, 6))\n",
    "        # ax[0].imshow(live_img_jpg)\n",
    "        # ax[1].imshow(demo_img_jpg)\n",
    "        # plt.show()\n",
    "        # recording demo image\n",
    "        \n",
    "    #print(type(run))\n",
    "    #print(rewards)\n",
    "    reward = rewards[\"{0:06d}\".format(run)]\n",
    "    # print(\"-\"*50, reward) #, pos_diff, orn_diff) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "id": "00ca7556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.859221155715826\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "    \n",
    "if distance == \"GP_pose\":\n",
    "    pos_diffs = []\n",
    "    orn_diffs = []\n",
    "    for pos_diff, orn_diff in scores_list:\n",
    "        pos_diffs.append(pos_diff)\n",
    "        orn_diffs.append(orn_diff)\n",
    "        \n",
    "    cmb_diffs = np.array(pos_diffs) + np.array(orn_diffs)\n",
    "    y = rew_list\n",
    "    pred = -1*cmb_diffs\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(y, pred, pos_label=1)\n",
    "    print(sklearn.metrics.auc(fpr, tpr))\n",
    "\n",
    "if distance == \"VS\":\n",
    "    rp_errs  = []\n",
    "    mean_flows = []\n",
    "    for rp_err, mean_flow in scores_list:\n",
    "        rp_errs.append(rp_err)\n",
    "        mean_flows.append(mean_flow)\n",
    "        \n",
    "    y = rew_list\n",
    "    pred = -1*np.array(rp_errs)\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(y, pred, pos_label=1)\n",
    "    print(sklearn.metrics.auc(fpr, tpr))\n",
    "\n",
    "if distance == \"cnn_sim\":\n",
    "    cnn_sim = []\n",
    "    for sim in scores_list:\n",
    "        cnn_sim.append(sim)\n",
    "        \n",
    "    y = rew_list\n",
    "    pred = np.array(cnn_sim)\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(y, pred, pos_label=1)\n",
    "    print(sklearn.metrics.auc(fpr, tpr))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f508d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454297ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600e85a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "servo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a1b46e996318d00ee8b18208f5e070fd91c5c69b566ca27af63ee58c19832482"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
