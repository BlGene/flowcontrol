{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "085c6878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Number of recordings: 30\n",
      "first /home/argusm/Desktop/Demonstrations/2023-01-24/14-18-38\n",
      "last  /home/argusm/Desktop/Demonstrations/2023-01-24/18-08-23\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "import logging\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, interact, Layout\n",
    "\n",
    "from flow_control.demo.playback_env_servo import PlaybackEnvServo\n",
    "\n",
    "root_dir = \"/home/argusm/Desktop/Demonstrations/2023-01-24/\"\n",
    "recordings = [os.path.join(root_dir, d) for d in sorted(os.listdir(root_dir)) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "\n",
    "print(\"Number of recordings:\", len(recordings))\n",
    "print(\"first\", recordings[0])\n",
    "print(\"last \", recordings[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d06ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the demonstration episodes\n",
    "playbacks = [PlaybackEnvServo(rec, load='keep') for rec in recordings[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9475a877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: May 20 2022 19:44:17\n",
      "INFO - 2023-06-13 16:10:39,929 - module - Loading ServoingModule...\n",
      "INFO - 2023-06-13 16:10:39,929 - module - Using RAFT\n",
      "INFO - 2023-06-13 16:10:40,546 - module - Loading recording (make take a bit): /home/argusm/Desktop/Demonstrations/2023-01-24/14-18-38\n",
      "INFO - 2023-06-13 16:10:40,878 - module - Loading time was 0.331 s\n",
      "INFO - 2023-06-13 16:10:42,230 - module_raft - Loading RAFT model, may take a bit...\n",
      "INFO - 2023-06-13 16:10:42,321 - module - Threshold: {18: 0.6789367811625633, 185: 0.5880885725701316, 235: 0.5880789829366987, 269: 0.5834225891593978, 327: 0.5014027643760912, 386: 0.4, 400: 1.0, 471: 0.8962306117608927, 539: 0.9175077815972037, 681: 0.46160886946574853, 796: 0.42284438410685893, 849: 0.4, 881: 0.4000662074167735}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 1.0\n"
     ]
    }
   ],
   "source": [
    "# Load Servoing Module\n",
    "from flow_control.servoing.module import ServoingModule\n",
    "control_config = dict(mode=\"pointcloud-abs-rotz\", threshold=0.40)\n",
    "servo_module = ServoingModule(recordings[0], control_config=control_config,\n",
    "                              start_paused=False, flow_module='RAFT')\n",
    "\n",
    "def similarity_from_reprojection(live_rgb, demo_rgb, demo_mask, return_images=False):\n",
    "    # evaluate the similarity via flow reprojection error\n",
    "    flow = servo_module.flow_module.step(demo_rgb, live_rgb)\n",
    "    warped = servo_module.flow_module.warp_image(live_rgb / 255.0, flow)\n",
    "    error = np.linalg.norm((warped - (demo_rgb / 255.0)), axis=2) * demo_mask\n",
    "    error = error.sum() / demo_mask.sum()\n",
    "    mean_flow = np.linalg.norm(flow[demo_mask],axis=1).mean()\n",
    "    if return_images:\n",
    "        return error, mean_flow, flow, warped\n",
    "    return error, mean_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f095624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good demos:   100.0 %\t 30 / 30\n",
      "Viable pairs: 96.7 %\t 870 / 900\n"
     ]
    }
   ],
   "source": [
    "demo_good = [True for pb in playbacks]\n",
    "\n",
    "bad_pair_arr = np.zeros((len(playbacks), len(playbacks)), dtype=bool)\n",
    "for idx in np.where(np.array(demo_good) == False)[0]:\n",
    "    bad_pair_arr[:,idx] = True\n",
    "    bad_pair_arr[idx,:] = True\n",
    "bad_pair_arr += np.eye(len(playbacks), len(playbacks), dtype=bool)\n",
    "#print(bad_pairs.astype(int))\n",
    "good_pairs = list(zip(*np.where(bad_pair_arr==False)))\n",
    "\n",
    "print(f\"Good demos:   {np.mean(demo_good)*100:.1f} %\\t\", sum(demo_good),\"/\",len(demo_good) )\n",
    "print(f\"Viable pairs: {(1-bad_pair_arr.mean())*100:.1f} %\\t\",sum(bad_pair_arr.flatten()==0),\"/\", bad_pair_arr.size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7270f435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 870/870 [03:33<00:00,  4.08it/s]\n"
     ]
    }
   ],
   "source": [
    "sim_scores = np.ones(bad_pair_arr.shape)  # lower is better\n",
    "mean_flows = np.zeros(bad_pair_arr.shape)\n",
    "\n",
    "for live_i, demo_i in tqdm(good_pairs):\n",
    "    live_rgb = playbacks[live_i][18].cam.get_image()[0]\n",
    "\n",
    "    demo_rgb =  playbacks[demo_i][18].cam.get_image()[0]\n",
    "    demo_mask =  playbacks[demo_i].get_fg_mask()\n",
    "    error, mean_flow = similarity_from_reprojection(live_rgb, demo_rgb, demo_mask)\n",
    "#     assert error <= 1.0\n",
    "    sim_scores[demo_i, live_i] = error\n",
    "    mean_flows[demo_i, live_i] = mean_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31b69c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "sim_l = sim_scores[demo_good]\n",
    "mean_flows_l = mean_flows[demo_good]\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_xlabel(\"reprojection\")\n",
    "ax.set_ylabel(\"mean flow\")\n",
    "ax.scatter(minmax_scale(sim_l), minmax_scale(mean_flows_l))\n",
    "plt.show()\n",
    "\n",
    "sim_scores_norm = np.ones(sim_scores.shape)\n",
    "w = .5\n",
    "sim_scores_norm[demo_good] = np.mean((1*minmax_scale(sim_l), w*minmax_scale(mean_flows_l)),axis=0)/(1+w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da92538d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "live episode [[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29]]\n",
      "demo episode [[ 9 13 19  1  2  9 22  4  3  5  1 19  5  1  3 11 12 22  5  7  3  3  6  4\n",
      "   3  2  3  3  3  3]]\n"
     ]
    }
   ],
   "source": [
    "good_episode = np.any(demo_good, axis=0)\n",
    "print(\"live episode\", np.arange(len(recordings))[good_episode])\n",
    "print(\"demo episode\", np.argmin(sim_scores_norm, axis=0)[good_episode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49232183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "N_DIGITS = 6\n",
    "\n",
    "def pos_orn_to_matrix(pos, orn):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        pos (x,y,z)\n",
    "        orn (q_x, q_y, q_z, w)\n",
    "    Returns:\n",
    "        mat: 4x4 homogeneous transformation\n",
    "    \"\"\"\n",
    "    assert len(pos) == 3\n",
    "    assert len(orn) == 4\n",
    "\n",
    "    mat = np.eye(4)\n",
    "\n",
    "    mat[:3, 3] = pos\n",
    "    mat[:3, :3] = R.from_quat(orn).as_matrix()\n",
    "    return mat\n",
    "\n",
    "\n",
    "def matrix_to_pos_orn(mat):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        mat: 4x4 homogeneous transformation\n",
    "    Returns:\n",
    "        tuple:\n",
    "            position: (x, y, z)\n",
    "            orientation: quaternion (q_x, q_y, q_z, w)\n",
    "    \"\"\"\n",
    "    pos = mat[:3, 3]\n",
    "    orn = R.from_matrix(mat[:3, :3]).as_quat()\n",
    "    return pos, orn\n",
    "\n",
    "\n",
    "def get_actions(meas_path, frame_idx):\n",
    "    servo_file = f\"{meas_path}/servo_keep.json\"\n",
    "    \n",
    "    with open(servo_file, 'r') as f_obj:\n",
    "        servo_keep = json.load(f_obj)\n",
    "    servo_keys = list(servo_keep.keys())\n",
    "    \n",
    "    for idx, key in enumerate(servo_keys):\n",
    "        key = int(key)\n",
    "        if key == frame_idx:\n",
    "            if idx + 1 < len(servo_keys):\n",
    "                next_frame_idx = int(servo_keys[idx + 1])\n",
    "                break\n",
    "            else:\n",
    "                raise ValueError(\"\")\n",
    "                \n",
    "    frame_path = f\"{meas_path}/frame_{frame_idx:0{N_DIGITS}d}.npz\"\n",
    "    next_frame_path = f\"{meas_path}/frame_{next_frame_idx:0{N_DIGITS}d}.npz\"\n",
    "                \n",
    "    frame_data = np.load(frame_path, allow_pickle=True)\n",
    "    next_frame_data = np.load(next_frame_path, allow_pickle=True)\n",
    "\n",
    "    current_pos = np.array(np.atleast_1d(frame_data['robot_state'])[0]['tcp_pos'])\n",
    "    current_orn = np.array(np.atleast_1d(frame_data['robot_state'])[0]['tcp_orn'])\n",
    "\n",
    "    next_pos = np.array(np.atleast_1d(next_frame_data['robot_state'])[0]['tcp_pos'])\n",
    "    next_orn = np.array(np.atleast_1d(next_frame_data['robot_state'])[0]['tcp_orn'])\n",
    "\n",
    "#     gripper_action = np.atleast_1d(next_frame_data['action'])[0]['motion'][2]\n",
    "\n",
    "    start_m = pos_orn_to_matrix(current_pos, current_orn)\n",
    "    finish_m = pos_orn_to_matrix(next_pos, next_orn)\n",
    "\n",
    "    rel_trf = np.linalg.inv(start_m) @ finish_m\n",
    "    rel_pos_orn = [list(x) for x in matrix_to_pos_orn(rel_trf)]\n",
    "\n",
    "    # Relative Actions\n",
    "    rel_pos = np.array(rel_pos_orn[0], dtype='float32')\n",
    "    rel_orn = np.array(rel_pos_orn[1], dtype='float32')\n",
    "#     gripper_action = np.array(gripper_action, dtype='float32')\n",
    "\n",
    "                \n",
    "    return rel_pos, rel_orn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19931d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_mse = []\n",
    "orn_mse = []\n",
    "\n",
    "for idx in range(len(recordings)):\n",
    "    query_demo = recordings[idx]\n",
    "    best_idx = np.argmin(sim_scores_norm[:, idx])\n",
    "    \n",
    "    best_demo = recordings [best_idx]\n",
    "    \n",
    "    q_pos, q_orn = get_actions(query_demo, 18)\n",
    "    d_pos, d_orn = get_actions(best_demo, 18)\n",
    "    \n",
    "    pmse = np.linalg.norm(q_pos - d_pos)\n",
    "    omse = np.linalg.norm(q_orn - d_orn)\n",
    "    \n",
    "    pos_mse.append(pmse)\n",
    "    orn_mse.append(omse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88913c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.036350686, 0.0075728735)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pos_mse), np.mean(orn_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdd53ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
