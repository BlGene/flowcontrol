{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50eb4b93",
   "metadata": {},
   "source": [
    "# Demo Manipulation\n",
    "\n",
    "## Export Data\n",
    "\n",
    "Feature extraction and matching work directly from images, so export these first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f54f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from tqdm.notebook import tqdm  # notebook-friendly progress bars\n",
    "from pathlib import Path\n",
    "\n",
    "from hloc import extract_features, match_features, reconstruction, visualization, pairs_from_exhaustive\n",
    "from hloc.visualization import plot_images, read_image, plot_keypoints\n",
    "from hloc.utils import viz_3d\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39568d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow_control.demo.playback_env_servo import PlaybackEnvServo\n",
    "from flow_control.localize.hloc_utils import export_images_by_parts\n",
    "\n",
    "# root_dir = Path(\"/home/argusm/CLUSTER/robot_recordings/flow/recombination/2023-01-24\")\n",
    "root_dir = Path(\"/home/argusm/Desktop/Demonstrations/2023-01-24\")\n",
    "parts_fn = root_dir / 'parts.json'\n",
    "hloc_root = root_dir.parent / ( str(root_dir.name) + '_hloc')\n",
    "\n",
    "mapping_dir = hloc_root / 'mapping'\n",
    "outputs = hloc_root / 'outputs'\n",
    "sfm_pairs = outputs / 'pairs-sfm.txt'\n",
    "loc_pairs = outputs / 'pairs-loc.txt'\n",
    "sfm_dir = outputs / 'sfm'\n",
    "features_path = outputs / 'features.h5'\n",
    "matches_path = outputs / 'matches.h5'\n",
    "!rm -rf $outputs\n",
    "!rm -rf $mapping_dir\n",
    "\n",
    "parts_references = export_images_by_parts(root_dir, parts_fn, mapping_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517be8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "references_all = [ref for ref_part in parts_references.values() for ref in ref_part]\n",
    "references_files = [p.relative_to(hloc_root).as_posix() for p in (hloc_root / 'mapping/').iterdir()]\n",
    "assert len(set(references_all)-set(references_files)) == 0\n",
    "references = parts_references['locate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a0a4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def get_info(demo_dir, frame_index):\n",
    "    arr = np.load(os.path.join(demo_dir, f\"frame_{frame_index:06d}.npz\"), allow_pickle=True)\n",
    "    return arr[\"robot_state\"].item(), arr[\"info\"].item()\n",
    "\n",
    "def pos_orn_to_matrix(pos, orn):\n",
    "    mat = np.eye(4)\n",
    "    if len(orn) == 4:\n",
    "        mat[:3, :3] = R.from_quat(orn).as_matrix()\n",
    "    elif len(orn) == 3:\n",
    "        mat[:3, :3] = R.from_euler('xyz', orn).as_matrix()\n",
    "    mat[:3, 3] = pos\n",
    "    return mat\n",
    "\n",
    "def get_tcp_pose(demo_dir, frame_index):\n",
    "    arr = np.load(os.path.join(demo_dir, f\"frame_{frame_index:06d}.npz\"),allow_pickle=True)\n",
    "    state = arr[\"robot_state\"].item()\n",
    "    return pos_orn_to_matrix(state[\"tcp_pos\"], state[\"tcp_orn\"])\n",
    "\n",
    "def get_extr_cal(demo_dir):\n",
    "    camera_info = np.load(Path(demo_dir) / \"camera_info.npz\", allow_pickle=True)\n",
    "    extr = camera_info[\"gripper_extrinsic_calibration\"]\n",
    "    return extr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e83a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcp_poses = {'locate': {}, 'grasp': {}, 'insert': {}}\n",
    "extr_cal = {}\n",
    "\n",
    "for part_key in parts_references:\n",
    "    tmp_ref = parts_references[part_key]\n",
    "    \n",
    "    for key in tmp_ref:\n",
    "        tmp = key[0:-5].strip().split('_')\n",
    "        frame_idx = int(tmp[1])\n",
    "        rec_name = tmp[0].split('/')[1]\n",
    "        rec_dir = root_dir / rec_name\n",
    "        \n",
    "        extr_cal[rec_name] = get_extr_cal(rec_dir)\n",
    "        tcp_poses[part_key][rec_name] = get_tcp_pose(rec_dir, frame_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2924dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images([read_image(hloc_root / r) for r in parts_references['insert'][:4]], dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c0e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(references), \"mapping images\")\n",
    "plot_images([read_image(hloc_root / r) for r in references[:4]], dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e468e57e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from flow_control.localize.hloc_utils import save_features_seg\n",
    "\n",
    "features_seg_path = outputs / 'features_seg.h5'\n",
    "\n",
    "feature_conf = extract_features.confs['superpoint_aachen']\n",
    "matcher_conf = match_features.confs['superglue']\n",
    "\n",
    "extract_features.main(feature_conf, hloc_root, image_list=references_all, feature_path=features_path)\n",
    "save_features_seg(root_dir, features_seg_path, features_path, references_all)\n",
    "\n",
    "pairs_from_exhaustive.main(sfm_pairs, image_list=references)\n",
    "match_features.main(matcher_conf, sfm_pairs, features=features_path, matches=matches_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7c318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hloc.utils.io import get_keypoints\n",
    "\n",
    "num_images = 4\n",
    "plot_images([read_image(hloc_root / r) for r in references[:num_images]], dpi=75)\n",
    "plot_keypoints([get_keypoints(features_path, r) for r in references[:num_images]], colors='lime', ps=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c5f1ac",
   "metadata": {},
   "source": [
    "## Load Match Database\n",
    "\n",
    "hloc saves all features and matches in a SQL database, so reading these is the easiest option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b06f705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hloc.utils.io import get_keypoints\n",
    "from flow_control.localize.hloc_utils import get_segmentation\n",
    "\n",
    "name0 = references[1]\n",
    "kps0, noise0 = get_keypoints(features_path, name0, return_uncertainty=True)\n",
    "kps0_seg, noise0 = get_keypoints(features_seg_path, name0, return_uncertainty=True)\n",
    "seg = get_segmentation(root_dir, name0)\n",
    "\n",
    "plot_images([read_image(hloc_root / r) for r in [name0, ]]+[seg], dpi=75)\n",
    "plot_keypoints([kps0, kps0_seg], colors='lime', ps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e241235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hloc.utils.io import get_matches\n",
    "from flow_control.localize.hloc_utils import kp_seg_filter\n",
    "\n",
    "name_q = references[1]\n",
    "name_d = references[3]\n",
    "\n",
    "matches, scores = get_matches(matches_path, name_q, name_d)\n",
    "kps_q, noise_q = get_keypoints(features_path, name_q, return_uncertainty=True)\n",
    "kps_d, noise_d = get_keypoints(features_path, name_d, return_uncertainty=True)\n",
    "kps_q_match = kps_q[matches[:, 0]]\n",
    "kps_d_match = kps_d[matches[:, 1]]\n",
    "\n",
    "#%prun in_seg = kp_seg_filter_pb(kps_d_match, name_d)\n",
    "in_seg = kp_seg_filter(kps_d_match, name_d, features_seg_path)\n",
    "\n",
    "print(\"in_seg\", in_seg)\n",
    "print(kps_d_match[in_seg].shape)\n",
    "\n",
    "kps_q_seg = kps_q_match[in_seg]\n",
    "kps_d_seg = kps_d_match[in_seg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b72c64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hloc.visualization import plot_matches\n",
    "from flow_control.localize.hloc_utils import get_playback, align_pointclouds\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "\n",
    "idx = 10\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "    \n",
    "os.makedirs(\"./mapping\", exist_ok=True)\n",
    "def find_best_demo(name_q, query_cam, references):\n",
    "    \n",
    "    results = {}\n",
    "    for name_d in tqdm(references):\n",
    "        if name_q == name_d:\n",
    "            continue\n",
    "        \n",
    "        res = align_pointclouds(root_dir, matches_path, features_path, features_seg_path,\n",
    "                                           name_q, name_d, query_cam=query_cam)\n",
    "        if res is None:\n",
    "            continue\n",
    "            \n",
    "        res['trf_est'] = res['trf_est']\n",
    "        res['num_inliers'] = res['num_inliers']\n",
    "        res['num_candidates'] = res['num_candidates']\n",
    "        res['in_score'] = res['num_candidates']\n",
    "        res['kps_q'] = res['kps_q']\n",
    "        res['kps_d'] = res['kps_d']\n",
    "        \n",
    "        results[name_d] = res\n",
    "        plot_images([read_image(hloc_root / r) for r in [name_q, name_d]], dpi=75)\n",
    "        plot_matches(res[\"kps_q\"], res[\"kps_d\"], a=0.1)\n",
    "        print(f\"Num. Inliers: {res['num_inliers']}\")\n",
    "#         print(res['kps_q'], res[\"kps_d\"])\n",
    "        plt.show()\n",
    "\n",
    "    results = {k: v for k, v in results.items() if v is not None}\n",
    "    results_sorted = sorted(results.items(), key=lambda t: -t[1][\"num_inliers\"])\n",
    "        \n",
    "    name_d_best = results_sorted[0][0]\n",
    "    \n",
    "    results['name_d_best'] = name_d_best\n",
    "    res_best = results_sorted[0][1]\n",
    "    return name_d_best, res_best, results\n",
    "\n",
    "def get_all_transformations(name_q, query_cam, references):\n",
    "    \n",
    "    results = {}\n",
    "    for name_d in tqdm(references):\n",
    "        if name_q == name_d:\n",
    "            continue\n",
    "        \n",
    "        res = align_pointclouds(root_dir, matches_path, features_path, features_seg_path,\n",
    "                                           name_q, name_d, query_cam=query_cam)\n",
    "        if res is None:\n",
    "            continue\n",
    "            \n",
    "        res['trf_est'] = res['trf_est']\n",
    "        res['num_inliers'] = res['num_inliers']\n",
    "        res['num_candidates'] = res['num_candidates']\n",
    "        res['in_score'] = res['num_candidates']\n",
    "        res['kps_q'] = res['kps_q']\n",
    "        res['kps_d'] = res['kps_d']\n",
    "        \n",
    "        results[name_d] = res\n",
    "        \n",
    "    return results\n",
    "\n",
    "results = {}\n",
    "for idx in range(30):    \n",
    "    name_q = references[idx]\n",
    "    pb, frame_index = get_playback(root_dir, name_q)\n",
    "    query_cam = pb[frame_index].cam\n",
    "\n",
    "    name_d_best, res_best, res = find_best_demo(name_q, query_cam, references)\n",
    "    results[idx] = res\n",
    "    \n",
    "# print(name_q, name_d_best)\n",
    "# trf_best = res_best[\"trf_est\"]\n",
    "\n",
    "# plot_images([read_image(hloc_root / r) for r in [name_q, name_d_best]], dpi=75)\n",
    "# plot_matches(res_best[\"kps_q\"], res_best[\"kps_d\"], a=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f351f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_to_world_tcp(align_trf, live_world_tcp, T_tcp_cam):\n",
    "    \"\"\"\n",
    "    The goal tcp position: T_tcp_wold.\n",
    "    \"\"\"\n",
    "    t_camlive_camdemo = np.linalg.inv(align_trf)\n",
    "    cam_base_est = live_world_tcp @ T_tcp_cam @ t_camlive_camdemo\n",
    "    tcp_base_est = cam_base_est @ np.linalg.inv(T_tcp_cam)\n",
    "    return tcp_base_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e38db70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(12,12))\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "def get_object_positions_angles(idx):\n",
    "    x_pos = []\n",
    "    y_pos = []\n",
    "    angles =[]\n",
    "    selected = []\n",
    "    rec_names = []\n",
    "    res = results[idx]\n",
    "\n",
    "    for key in res.keys():\n",
    "        if key == 'name_d_best':\n",
    "            continue\n",
    "        tmp = key.strip().split('_')[0]\n",
    "        rec_name = tmp.split('/')[1]\n",
    "\n",
    "        t1 = tcp_poses['locate'][rec_name]\n",
    "        t2 = tcp_poses['insert'][rec_name]\n",
    "\n",
    "        trf_live_to_demo = abs_to_world_tcp(res[key]['trf_est'], np.eye(4), extr_cal[rec_name])\n",
    "        final_loc = trf_live_to_demo @ np.linalg.inv(t1) @ t2\n",
    "\n",
    "        rot_mat = final_loc[0:3, 0:3]\n",
    "        r = R.from_matrix(rot_mat)\n",
    "        r = r.as_euler('zyx', degrees=True)\n",
    "\n",
    "        label = rec_name\n",
    "        if rec_name in results[idx]['name_d_best']:\n",
    "            label += \"*\"\n",
    "            selected.append(True)\n",
    "        else:\n",
    "            selected.append(False)\n",
    "\n",
    "        x_pos.append(final_loc[0, 3])\n",
    "        y_pos.append(final_loc[1, 3])\n",
    "        angles.append(r[0])\n",
    "        rec_names.append(rec_name)\n",
    "        \n",
    "    return x_pos, y_pos, angles, selected, rec_names\n",
    "\n",
    "object_data = {}\n",
    "\n",
    "for idx in range(30):\n",
    "    x_pos, y_pos, angles, selected, rec_names = get_object_positions_angles(idx)\n",
    "    object_data[idx] = {'xpos': x_pos, 'ypos': y_pos, 'angles': angles, 'selected': selected, 'rec_names': rec_names}\n",
    "    \n",
    "#         ax.scatter(final_loc[0, 3], final_loc[1, 3], r[0], s=results[key]['num_inliers']*20, label=label)\n",
    "\n",
    "#     ax.set_xlabel('x')\n",
    "#     ax.set_ylabel('y')\n",
    "#     ax.set_zlabel('angle')\n",
    "#     ax.legend()\n",
    "    # ax.show()\n",
    "#     print(name_d_best)\n",
    "\n",
    "    # plot_images([read_image(hloc_root / r) for r in [name_q, name_d_best]], dpi=75)\n",
    "    # plot_matches(res[\"kps_q\"], res[\"kps_d\"], a=0.1)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb214a19",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cluster(x_pos, y_pos, angles, selected):\n",
    "    print(selected)\n",
    "    sel = np.where(selected == True)[0][0]\n",
    "    \n",
    "    sel_xpos = x_pos[sel]\n",
    "    sel_ypos = y_pos[sel]\n",
    "    \n",
    "    cluster_lengths = []\n",
    "    clusters = []\n",
    "    \n",
    "    for idx in range(len(x_pos)):\n",
    "        xdiff = np.abs(x_pos[idx] - x_pos)\n",
    "        ydiff = np.abs(y_pos[idx] - y_pos)\n",
    "        angle_diff = np.abs(angles[idx] - angles)\n",
    "        \n",
    "        cluster = np.where((xdiff < 0.05) & (ydiff < 0.05) & (angle_diff < 20.0))[0]\n",
    "        \n",
    "        cluster_lengths.append(len(cluster))\n",
    "        clusters.append(cluster)\n",
    "        \n",
    "#     print(clusters, cluster_lengths)\n",
    "#     print(cluster_lengths[sel])\n",
    "\n",
    "    return cluster_lengths, clusters\n",
    "    \n",
    "def plot_3d(query_idx):\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    \n",
    "    xpos = np.array(object_data[query_idx]['xpos'])\n",
    "    ypos = np.array(object_data[query_idx]['xpos'])\n",
    "    angles = np.array(object_data[query_idx]['angles'])\n",
    "    selected = np.array(object_data[query_idx]['selected'])\n",
    "    rec_names = object_data[query_idx]['rec_names']\n",
    "    \n",
    "    cluster_lengths, clusters = cluster(xpos, ypos, angles, selected)\n",
    "    print(f\"Cluster Sizes: {cluster_lengths}\")\n",
    "    print(f\"Clusters: {clusters}\")\n",
    "    max_cluster_size = np.max(cluster_lengths)\n",
    "    \n",
    "    rec_names_clusters = []\n",
    "    \n",
    "    for tmp_i, key in enumerate(results[query_idx].keys()):\n",
    "        if key == 'name_d_best':\n",
    "            continue\n",
    "        label = rec_names[tmp_i]\n",
    "        if rec_names[tmp_i] in results[query_idx]['name_d_best']:\n",
    "            label = label + '*'\n",
    "        if cluster_lengths[tmp_i] == max_cluster_size:\n",
    "            rec_names_clusters.append(rec_names[tmp_i])\n",
    "            label += '+'\n",
    "        ax.scatter(xpos[tmp_i], ypos[tmp_i], angles[tmp_i], s=results[query_idx][key]['num_inliers'] * 20, label=label)\n",
    "\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('angle')\n",
    "    ax.legend()\n",
    "    \n",
    "    name_q = references[query_idx]\n",
    "    name_d_selected = results[query_idx]['name_d_best']\n",
    "    \n",
    "    # Inlier selection\n",
    "    plot_images([read_image(hloc_root / r) for r in [name_q, name_d_selected]], dpi=75)\n",
    "    plot_matches(results[query_idx][name_d_selected][\"kps_q\"], results[query_idx][name_d_selected][\"kps_d\"], a=0.1)\n",
    "    \n",
    "    # Clustering\n",
    "    for name_d in references:\n",
    "        for i in range(len(rec_names_clusters)):\n",
    "            if rec_names_clusters[i] in name_d:\n",
    "                plot_images([read_image(hloc_root / r) for r in [name_q, name_d]], dpi=75)\n",
    "                plot_matches(results[query_idx][name_d][\"kps_q\"], results[query_idx][name_d][\"kps_d\"], a=0.1)\n",
    "                \n",
    "                print(f\"Recording_name: {rec_names_clusters[i]}\")\n",
    "    \n",
    "# for plot_idx in range(30):\n",
    "#     plot_3d(plot_idx)\n",
    "\n",
    "plot_3d(24)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5719ad03",
   "metadata": {},
   "source": [
    "for name_q in references:\n",
    "    name_d_best, res_best = find_best_demo(name_q, references)\n",
    "    print(name_q, name_d_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cc7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import open3d as o3d\n",
    "from flow_control.localize.hloc_utils import get_pointcloud, get_segmented_pointcloud\n",
    "\n",
    "def draw_registration_result(source_arr, target_arr, transformation, color=\"rgb\"):\n",
    "    source = o3d.geometry.PointCloud()\n",
    "    source.points = o3d.utility.Vector3dVector(source_arr[:, :3])\n",
    "    target = o3d.geometry.PointCloud()\n",
    "    target.points = o3d.utility.Vector3dVector(target_arr[:, :3])\n",
    "    \n",
    "    if color == \"rgb\":\n",
    "        source.colors = o3d.utility.Vector3dVector(source_arr[:, 4:7] )\n",
    "        target.colors = o3d.utility.Vector3dVector(target_arr[:, 4:7] )\n",
    "        source_temp = copy.deepcopy(source)\n",
    "        target_temp = copy.deepcopy(target)\n",
    "    else:\n",
    "        source_temp = copy.deepcopy(source)\n",
    "        target_temp = copy.deepcopy(target)\n",
    "        source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "        target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "        \n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "    \n",
    "pc_full_q, _ = get_segmented_pointcloud(name_q, root_dir=root_dir)\n",
    "pc_full_d, bbox = get_segmented_pointcloud(name_d_best, root_dir=root_dir)\n",
    "# pc_full_q, bbox = get_segmented_pointcloud(name_q, root_dir=root_dir, is_live=True, trf=np.linalg.inv(trf_best), bbox=bbox)\n",
    "# pc_full_q, bbox = get_segmented_pointcloud(name_q, root_dir=root_dir)\n",
    "\n",
    "# o3d.visualization.draw_geometries([pc, bbox])\n",
    "\n",
    "print(pc_full_q.shape)\n",
    "draw_registration_result(pc_full_q, pc_full_d, trf_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e6ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_q = o3d.cuda.pybind.geometry.PointCloud()\n",
    "pcd_q.points = o3d.utility.Vector3dVector(pc_full_q[:, 0:3])\n",
    "\n",
    "pcd_d = o3d.cuda.pybind.geometry.PointCloud()\n",
    "pcd_d.points = o3d.utility.Vector3dVector(pc_full_d[:, 0:3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657d5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = o3d.pipelines.registration.evaluate_registration(\n",
    "    pcd_q, pcd_d, max_correspondence_distance=0.02, transformation=trf_best)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf09a498",
   "metadata": {},
   "source": [
    "# Localization (Live Inferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48621b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from PIL import Image\n",
    "def create_query_image(query_cam):\n",
    "    query_dir = hloc_root / \"query\"\n",
    "    Path(query_dir).mkdir(parents=True, exist_ok=True)\n",
    "    image_path_query = query_dir / \"live.jpg\"\n",
    "    image_arr = query_cam.get_image()[0]\n",
    "    Image.fromarray(image_arr).save(image_path_query)\n",
    "    return image_path_query.relative_to(hloc_root).as_posix()\n",
    "\n",
    "name_q = references[0]\n",
    "pb, frame_index = get_playback(root_dir, name_q)\n",
    "query_cam = pb[frame_index].cam\n",
    "query = create_query_image(query_cam)\n",
    "\n",
    "references_live = [x for x in references if x != name_q]\n",
    "extract_features.main(feature_conf, hloc_root, image_list=[query], feature_path=features_path, overwrite=True)\n",
    "pairs_from_exhaustive.main(loc_pairs, image_list=[query], ref_list=references_live)\n",
    "match_features.main(matcher_conf, loc_pairs, features=features_path, matches=matches_path, overwrite=True)\n",
    "name_d_best_live, res_best_live = find_best_demo(query, qery_cam, references_live)\n",
    "\n",
    "print(name_q, name_d_best_live)\n",
    "plot_images([read_image(hloc_root / r) for r in [name_q, name_d_best_live]], dpi=75)\n",
    "plot_matches(res_best_live[\"kps_q\"], res_best_live[\"kps_d\"], a=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f978a088",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de90c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow_control.localize.hloc_utils import get_playback\n",
    "\n",
    "name_q = selection_hloc.parts_references['locate'][0]\n",
    "pb, frame_index = get_playback(root_dir, name_q)\n",
    "query_cam = pb[frame_index].cam\n",
    "name_best, res_best = selection_hloc.get_best_demo(query_cam)\n",
    "print(name_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09420f0d",
   "metadata": {},
   "source": [
    "# Original File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fbdb5c",
   "metadata": {},
   "source": [
    "In this notebook, we will build a 3D map of a scene from a small set of images and then localize an image downloaded from the Internet. This demo was contributed by [Philipp Lindenberger](https://github.com/Phil26AT/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e663b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tqdm, tqdm.notebook\n",
    "tqdm.tqdm = tqdm.notebook.tqdm  # notebook-friendly progress bars\n",
    "from pathlib import Path\n",
    "\n",
    "from hloc import extract_features, match_features, reconstruction, visualization, pairs_from_exhaustive\n",
    "from hloc.visualization import plot_images, read_image, plot_keypoints\n",
    "from hloc.utils import viz_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72ac394",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Here we define some output paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f376de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = Path('datasets/sacre_coeur')\n",
    "outputs = Path('outputs/demo/')\n",
    "!rm -rf $outputs\n",
    "sfm_pairs = outputs / 'pairs-sfm.txt'\n",
    "loc_pairs = outputs / 'pairs-loc.txt'\n",
    "sfm_dir = outputs / 'sfm'\n",
    "features = outputs / 'features.h5'\n",
    "matches = outputs / 'matches.h5'\n",
    "\n",
    "feature_conf = extract_features.confs['superpoint_aachen']\n",
    "matcher_conf = match_features.confs['superglue']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc7b21e",
   "metadata": {},
   "source": [
    "# 3D mapping\n",
    "First we list the images used for mapping. These are all day-time shots of Sacre Coeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = [p.relative_to(images).as_posix() for p in (images / 'mapping/').iterdir()]\n",
    "print(len(references), \"mapping images\")\n",
    "plot_images([read_image(images / r) for r in references[:4]], dpi=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23739ad",
   "metadata": {},
   "source": [
    "Then we extract features and match them across image pairs. Since we deal with few images, we simply match all pairs exhaustively. For larger scenes, we would use image retrieval, as demonstrated in the other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd2df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features.main(feature_conf, images, image_list=references, feature_path=features)\n",
    "pairs_from_exhaustive.main(sfm_pairs, image_list=references)\n",
    "match_features.main(matcher_conf, sfm_pairs, features=features, matches=matches);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf9adf4",
   "metadata": {},
   "source": [
    "The we run incremental Structure-From-Motion and display the reconstructed 3D model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52fe785",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = reconstruction.main(sfm_dir, images, sfm_pairs, features, matches, image_list=references)\n",
    "fig = viz_3d.init_figure()\n",
    "viz_3d.plot_reconstruction(fig, model, color='rgba(255,0,0,0.5)', name=\"mapping\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478094d",
   "metadata": {},
   "source": [
    "We also visualize which keypoints were triangulated into the 3D model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c20e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.visualize_sfm_2d(model, images, color_by='visibility', n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b08268",
   "metadata": {},
   "source": [
    "# Localization\n",
    "Now that we have a 3D map of the scene, we can localize any image. To demonstrate this, we download [a night-time image from Wikimedia](https://commons.wikimedia.org/wiki/File:Paris_-_Basilique_du_Sacr%C3%A9_Coeur,_Montmartre_-_panoramio.jpg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f07f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://upload.wikimedia.org/wikipedia/commons/5/53/Paris_-_Basilique_du_Sacr%C3%A9_Coeur%2C_Montmartre_-_panoramio.jpg\"\n",
    "# try other queries by uncommenting their url\n",
    "# url = \"https://upload.wikimedia.org/wikipedia/commons/5/59/Basilique_du_Sacr%C3%A9-C%C5%93ur_%285430392880%29.jpg\"\n",
    "# url = \"https://upload.wikimedia.org/wikipedia/commons/8/8e/Sacr%C3%A9_C%C5%93ur_at_night%21_%285865355326%29.jpg\"\n",
    "query = 'query/night.jpg'\n",
    "!mkdir -p $images/query && wget $url -O $images/$query -q\n",
    "plot_images([read_image(images / query)], dpi=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a035ca4",
   "metadata": {},
   "source": [
    "Again, we extract features for the query and match them exhaustively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7626a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features.main(feature_conf, images, image_list=[query], feature_path=features, overwrite=True)\n",
    "pairs_from_exhaustive.main(loc_pairs, image_list=[query], ref_list=references)\n",
    "match_features.main(matcher_conf, loc_pairs, features=features, matches=matches, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b037419",
   "metadata": {},
   "source": [
    "We read the EXIF data of the query to infer a rough initial estimate of camera parameters like the focal length. Then we estimate the absolute camera pose using PnP+RANSAC and refine the camera parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd559ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycolmap\n",
    "from hloc.localize_sfm import QueryLocalizer, pose_from_cluster\n",
    "\n",
    "camera = pycolmap.infer_camera_from_image(images / query)\n",
    "ref_ids = [model.find_image_with_name(r).image_id for r in references]\n",
    "conf = {\n",
    "    'estimation': {'ransac': {'max_error': 12}},\n",
    "    'refinement': {'refine_focal_length': True, 'refine_extra_params': True},\n",
    "}\n",
    "localizer = QueryLocalizer(model, conf)\n",
    "ret, log = pose_from_cluster(localizer, query, camera, ref_ids, features, matches)\n",
    "\n",
    "print(f'found {ret[\"num_inliers\"]}/{len(ret[\"inliers\"])} inlier correspondences.')\n",
    "visualization.visualize_loc_from_log(images, query, log, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791e5518",
   "metadata": {},
   "source": [
    "We visualize the correspondences between the query images a few mapping images. We can also visualize the estimated camera pose in the 3D map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ab5306",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = pycolmap.Image(tvec=ret['tvec'], qvec=ret['qvec'])\n",
    "viz_3d.plot_camera_colmap(fig, pose, camera, color='rgba(0,255,0,0.5)', name=query)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
