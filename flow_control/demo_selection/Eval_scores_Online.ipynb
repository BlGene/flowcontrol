{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0da5619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import logging\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, interact, Layout\n",
    "\n",
    "from flow_control.servoing.playback_env_servo import PlaybackEnvServo\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")\n",
    "\n",
    "root_dir = \"/misc/student/nayaka/paper/flowcontrol/flow_control/demo/tmp_new/cnn_new\"\n",
    "task = \"shape_sorting\"\n",
    "object_selected = \"trapeze\" \n",
    "task_variant = \"rP\"  # rotation plus (+-pi)\n",
    "\n",
    "\n",
    "def get_recordings(directory):\n",
    "    return sorted([os.path.join(directory, rec) for rec in os.listdir(directory) if os.path.isdir(os.path.join(directory, rec))])\n",
    "\n",
    "recordings = get_recordings(root_dir)\n",
    "\n",
    "print(\"Number of recordings:\", len(recordings))\n",
    "print(\"first\", recordings[0])\n",
    "print(\"last \", recordings[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f19281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "live_seed, demo_seed = 0, 0\n",
    "demo_dir = recordings[demo_seed]\n",
    "print(f\"live: {live_seed} demo: {demo_seed} @ {demo_dir}\")\n",
    "print()\n",
    "\n",
    "demo = PlaybackEnvServo(demo_dir, load=\"keep\")\n",
    "print(\"demo keep:\", list(demo.keep_dict.keys()))\n",
    "print()\n",
    "\n",
    "demo_parts_fn = os.path.join(root_dir, \"demo_parts_manual3.json\")\n",
    "with open(demo_parts_fn) as f_obj:\n",
    "    demo_parts = json.load(f_obj)\n",
    "\n",
    "demo_keep = sorted(list(demo.keep_dict.keys()))\n",
    "keep_all = copy.copy(demo.keep_dict)\n",
    "keep_parts = {}\n",
    "for p in demo_parts[str(demo_seed)]:\n",
    "    if p[\"start\"] == 0:\n",
    "        p_start = -1\n",
    "    else:\n",
    "        p_start = p[\"start\"]\n",
    "        \n",
    "    parts = []\n",
    "    for demo_index in demo_keep:\n",
    "        if p_start < demo_index and p[\"end\"] >= demo_index:\n",
    "            parts.append(demo_index)\n",
    "    print(p[\"name\"], '\\t', parts)\n",
    "    \n",
    "    keep_parts[p[\"name\"]] = dict([(i, demo.keep_dict[i]) for i in parts])\n",
    "    print(keep_parts[p[\"name\"]])\n",
    "# set keep_dict to first part\n",
    "demo.keep_dict = keep_parts[\"locate\"]\n",
    "#servo_module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2b9a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "playbacks = [PlaybackEnvServo(rec, load='all') for rec in recordings[:]]\n",
    "good_demos = [int(key) for key in demo_parts.keys()]\n",
    "demo_good = good_demos\n",
    "demo_good = np.array(demo_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual Similarity scores\n",
    "\n",
    "# from sklearn.preprocessing import minmax_scale\n",
    "# # Load Servoing Module\n",
    "# from flow_control.servoing.module import ServoingModule\n",
    "# control_config = dict(mode=\"pointcloud-abs-rotz\", threshold=0.40)\n",
    "# servo_module = ServoingModule(demo_dir, control_config=control_config,\n",
    "#                               start_paused=False)\n",
    "\n",
    "# def similarity_from_reprojection(live_rgb, demo_rgb, demo_mask, return_images=False):\n",
    "#     # evaluate the similarity via flow reprojection error\n",
    "#     flow = servo_module.flow_module.step(demo_rgb, live_rgb)\n",
    "#     warped = servo_module.flow_module.warp_image(live_rgb / 255.0, flow)\n",
    "#     error = np.linalg.norm((warped - (demo_rgb / 255.0)), axis=2) * demo_mask\n",
    "#     error = error.sum() / demo_mask.sum()\n",
    "#     mean_flow = np.linalg.norm(flow[demo_mask],axis=1).mean()\n",
    "#     if return_images:\n",
    "#         return error, mean_flow, flow, warped\n",
    "#     return error, mean_flow\n",
    "\n",
    "# def normalize_errors(errors, flows):\n",
    "#     errors_l = errors[demo_good]\n",
    "#     mean_flows_l = flows[demo_good]\n",
    "#     errors_norm = np.ones(errors.shape)\n",
    "#     w = .5\n",
    "#     errors_norm[demo_good] = np.mean((1*minmax_scale(errors_l), w*minmax_scale(mean_flows_l)),axis=0)/(1+w) \n",
    "    \n",
    "#     return errors_norm\n",
    "\n",
    "\n",
    "# def compute_current_scores(playbacks, current_rgb, demo_parts, demo_good, traj_idx=0, live_seed=0):    \n",
    "#     sim_errors = np.ones(len(playbacks)) # lower is better\n",
    "#     mean_flows = np.zeros(len(playbacks))\n",
    "\n",
    "#     for demo_seed in demo_good:\n",
    "#         if traj_idx == 0 and demo_seed == live_seed:\n",
    "#             continue\n",
    "#         start_idx = demo_parts[str(demo_seed)][traj_idx]['start']\n",
    "#         demo_rgb =  playbacks[demo_seed][start_idx].cam.get_image()[0]\n",
    "#         demo_mask =  playbacks[demo_seed].fg_masks[start_idx]\n",
    "#         error, mean_flow = similarity_from_reprojection(current_rgb, demo_rgb, demo_mask)\n",
    "#         sim_errors[demo_seed] = error\n",
    "#         mean_flows[demo_seed] = mean_flow\n",
    "#     errors_norm = normalize_errors(sim_errors, mean_flows)\n",
    "#     scores = 1 - errors_norm\n",
    "    \n",
    "#     return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea40124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipdb\n",
    "def split_keypoints(pb, demo_part):\n",
    "    demo_keep = sorted(list(pb.keep_dict.keys()))\n",
    "    keep_all = copy.copy(pb.keep_dict)\n",
    "    keep_parts = {}\n",
    "    for p in demo_part:\n",
    "        if p[\"start\"] == 0:\n",
    "            p_start = -1\n",
    "        else:\n",
    "            p_start = p[\"start\"]\n",
    "\n",
    "        parts = []\n",
    "        for demo_index in demo_keep:\n",
    "            if p_start < demo_index and p[\"end\"] >= demo_index:\n",
    "                parts.append(demo_index)    \n",
    "\n",
    "        keep_parts[p[\"name\"]] = parts\n",
    "    keep_parts['grasp'].append(keep_parts['insert'][0])\n",
    "    return keep_parts\n",
    "\n",
    "keypoint_info = {}\n",
    "\n",
    "for demo_seed in good_demos:\n",
    "    keypoint_info[demo_seed] = split_keypoints(playbacks[demo_seed], demo_parts[str(demo_seed)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5689b169",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "1. Update this part depending on the model\n",
    "2. Use the created model as an argument in the compute_current_scores function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72658fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_sim.network import SimilarityNet\n",
    "import ipdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "\n",
    "model0 = nn.DataParallel(SimilarityNet(), device_ids=[0])\n",
    "model0.cuda()\n",
    "\n",
    "load_model0 = './train_sim/models/models_part0/simNet_500.pth'\n",
    "\n",
    "if load_model0 is not None:\n",
    "    print(f\"Loading Model: {load_model0}\")\n",
    "    model0.load_state_dict(torch.load(load_model0))\n",
    "    \n",
    "    model0 = nn.DataParallel(SimilarityNet(), device_ids=[0])\n",
    "\n",
    "    model0.cuda()\n",
    "    \n",
    "model1 = nn.DataParallel(SimilarityNet(), device_ids=[0])\n",
    "model1.cuda()\n",
    "load_model1 = './train_sim/models/simNet_280.pth'\n",
    "\n",
    "if load_model1 is not None:\n",
    "    print(f\"Loading Model: {load_model1}\")\n",
    "    model1.load_state_dict(torch.load(load_model1))\n",
    "    \n",
    "transforms = T.Compose([T.ToTensor()])\n",
    "\n",
    "model0.eval()\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b95b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute scores using the trained model\n",
    "# Stack input images (live and demo) and pass them through the model\n",
    "\n",
    "def compute_current_scores(model, playbacks, current_rgb, demo_parts, demo_good, traj_idx=0, live_seed=0):    \n",
    "    sim_errors = np.ones(len(playbacks)) # lower is better\n",
    "    mean_flows = np.zeros(len(playbacks))\n",
    "    \n",
    "    transforms = T.Compose([T.ToTensor()])\n",
    "        \n",
    "    inputs = []\n",
    "    \n",
    "    current_rgb = transforms(np.float32(current_rgb / 255.0))\n",
    "\n",
    "    for demo_idx in demo_good:\n",
    "        start_idx = demo_parts[str(demo_idx)][traj_idx]['start']\n",
    "        demo_rgb =  playbacks[demo_idx][start_idx].cam.get_image()[0]\n",
    "        demo_mask =  playbacks[demo_idx].fg_masks[start_idx]\n",
    "        \n",
    "        demo_rgb =  transforms(np.float32(demo_rgb / 255.0))\n",
    "                \n",
    "        inp = torch.cat((current_rgb, demo_rgb), dim=0).cuda()\n",
    "        inputs.append(inp[None, :])\n",
    "    \n",
    "    # After concatenation, shape: [Num_demos, 6, 256, 256]\n",
    "    inputs = torch.cat(inputs, 0)\n",
    "    out = model(inputs)\n",
    "    out = out[:, 0]\n",
    "        \n",
    "    return out.detach().cpu().numpy()\n",
    "\n",
    "# cr = np.zeros((256, 256, 3))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     out = compute_current_scores(playbacks, cr, demo_parts, demo_good, 0, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c31d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "from flow_control.servoing.module import ServoingModule\n",
    "from gym_grasping.envs.robot_sim_env import RobotSimEnv\n",
    "from flow_control.runner import evaluate_control\n",
    "import ipdb\n",
    "\n",
    "def eval_cmb(playbacks, live_seed, demo_parts, keypoint_info):\n",
    "    renderer = 'egl'\n",
    "    # Instantiate env\n",
    "    env = RobotSimEnv(task='shape_sorting', renderer=renderer, act_type='continuous',\n",
    "                      initial_pose='close', max_steps=500, control='absolute-full',\n",
    "                      img_size=(256, 256), param_randomize=(\"geom\",), seed=int(live_seed),\n",
    "                      task_info=dict(object_rot_range={\"rP\":pi/2.,\"rR\":pi/6.}[task_variant]))\n",
    "    \n",
    "    traj_map = {0: 'locate', 1: 'grasp', 2: 'insert'}\n",
    "    \n",
    "    for idx in range(3):\n",
    "        \n",
    "        state, _, _, _ = env.step(None)\n",
    "        current_rgb = state['rgb_gripper']\n",
    "        \n",
    "        scores = compute_current_scores(model, playbacks, current_rgb, demo_parts, demo_good, traj_idx=idx, live_seed=live_seed)\n",
    "\n",
    "        best_demo_idx = np.argmax(scores)\n",
    "        \n",
    "        best_demo = recordings[best_demo_idx]\n",
    "        kp_info = keypoint_info[best_demo_idx]\n",
    "        kps = kp_info[traj_map[idx]]\n",
    "                \n",
    "        servo_module = ServoingModule(best_demo, control_config=control_config,\n",
    "                                      start_paused=False, plot=False, plot_save_dir=None,\n",
    "                                      load=kps)\n",
    "        _, reward, _, info = evaluate_control(env, servo_module, max_steps=130, save_dir=None,\n",
    "                                             initial_align=True if idx == 0 else False)\n",
    "    del env\n",
    "    del servo_module\n",
    "    return reward\n",
    "\n",
    "# eval_cmb(playbacks, 1, demo_parts, keypoint_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c02f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_live_seeds = 60\n",
    "rewards = np.zeros((num_live_seeds))\n",
    "\n",
    "seeds = range(60, 60 + num_live_seeds)\n",
    "for live_idx, live_seed in enumerate(seeds):\n",
    "    reward = eval_cmb(playbacks, live_seed, demo_parts, keypoint_info)\n",
    "    rewards[live_idx] = reward\n",
    "    \n",
    "np.savez('cnn_rewards_3parts.npz', rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d09dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rewards, np.mean(rewards))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dllab",
   "language": "python",
   "name": "dllab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f50f8446da7fd9aa801340c473bbd4e01f93aa3df9827eb3dce1563b2048a79c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
