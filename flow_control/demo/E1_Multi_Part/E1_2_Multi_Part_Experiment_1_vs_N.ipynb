{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eac98bd",
   "metadata": {},
   "source": [
    "# Multi-Part Experiment 1 vs N\n",
    "\n",
    "To use this notebook, you already should have run the following notebooks:\n",
    "1. E1_0_Record_and_Segment.ipynb\n",
    "2. E1_1_Multi_Part_Selection.ipynb\n",
    "\n",
    "Summary:\n",
    "1. This notebook uses already computed scores stored as npz files\n",
    "2. For each part, compute scores at the front live (current_rgb vs first frame of the part)\n",
    "3. Compute full trajectory from current state to the goal state\n",
    "\n",
    "We compute rewards for the shapes: {'trapeze'} using scoring functions {'sum', 'prod'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e64e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "import unittest\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "from gym_grasping.envs.robot_sim_env import RobotSimEnv\n",
    "from flow_control.demo.demo_episode_recorder import record_sim\n",
    "from flow_control.runner import evaluate_control\n",
    "from flow_control.servoing.module import ServoingModule\n",
    "from flow_control.servoing.playback_env_servo import PlaybackEnvServo\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, interact, Layout\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import getpass\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "experiment = \"multi_part\"\n",
    "\n",
    "renderer = 'debug'\n",
    "task_variant = 'rP'\n",
    "\n",
    "def get_data_dir():\n",
    "    username = getpass.getuser()\n",
    "    if username == \"argusm\":\n",
    "        return \"/tmp/flow_experiments3\"\n",
    "    elif username == \"nayakab\":\n",
    "        return \"../tmp\"\n",
    "\n",
    "data_dir = get_data_dir()\n",
    "\n",
    "root_dir = os.path.join(data_dir, experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8950f0b7",
   "metadata": {},
   "source": [
    "## Load all Demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recordings(directory):\n",
    "    return sorted([os.path.join(directory, rec) for rec in os.listdir(directory) if os.path.isdir(os.path.join(directory, rec))])\n",
    "\n",
    "recordings = get_recordings(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72960233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the demonstration episodes\n",
    "playbacks = [PlaybackEnvServo(rec) for rec in recordings[:]]\n",
    "\n",
    "# Plot the demonstrations\n",
    "%matplotlib notebook\n",
    "fig, ax = plt.subplots(1,figsize=(8, 6))\n",
    "fig.suptitle(\"Demonstration Frames\")\n",
    "ax.set_axis_off()\n",
    "image_h = ax.imshow(playbacks[0].cam.get_image()[0])\n",
    "\n",
    "def update(demo_index, frame_index):\n",
    "    image = playbacks[demo_index][frame_index].cam.get_image()[0]\n",
    "    image_h.set_data(image)\n",
    "    fig.canvas.draw_idle()\n",
    "    print(\"wp_name:\", playbacks[demo_index][frame_index].get_info()[\"wp_name\"])\n",
    "    fg_mask = playbacks[demo_index].get_fg_mask()\n",
    "    if fg_mask is not None:\n",
    "        print(\"percent fg:\", np.mean(fg_mask)*100)\n",
    "    \n",
    "slider_w = widgets.IntSlider(min=0, max=len(playbacks)-1, step=1, value=0,\n",
    "                             layout=Layout(width='70%'))\n",
    "slider_i = widgets.IntSlider(min=0, max=200-1, step=1, value=0,\n",
    "                             layout=Layout(width='70%'))\n",
    "\n",
    "interact(update, demo_index=slider_w, frame_index=slider_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddef42cb",
   "metadata": {},
   "source": [
    "# Read scores (errors) from the stored files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e691f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_matrix_2_part = np.load(f\"{root_dir}/error_matrix_2_part.npz\")['arr_0']\n",
    "score_matrix_2_part = 1 - error_matrix_2_part\n",
    "\n",
    "error_matrix_3_part_1 = np.load(f\"{root_dir}/error_matrix_3_part_1.npz\")['arr_0']\n",
    "score_matrix_3_part_1 = 1 - error_matrix_3_part_1\n",
    "\n",
    "error_matrix_3_part_2 = np.load(f\"{root_dir}/error_matrix_3_part_2.npz\")['arr_0']\n",
    "score_matrix_3_part_2 = 1 - error_matrix_3_part_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get good demonstrations and demonstration part information\n",
    "def filter_demo(pb):\n",
    "    return pb[-1].data['rew'] > 0 and np.mean(pb.get_fg_mask()) > 0.005\n",
    "\n",
    "demo_good = [filter_demo(pb) for pb in playbacks]\n",
    "good_demonstrations = np.where(demo_good)[0]\n",
    "\n",
    "good_demonstrations = [int(x) for x in good_demonstrations]\n",
    "live_seeds = good_demonstrations\n",
    "print(good_demonstrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a2c1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load demo segmentation file\n",
    "demo_seg_file = f'{root_dir}/demo_parts_manual2.json'\n",
    "fp = open(demo_seg_file)\n",
    "demo_2parts = json.load(fp)\n",
    "\n",
    "demo_seg_file = f'{root_dir}/demo_parts_manual3.json'\n",
    "fp = open(demo_seg_file)\n",
    "demo_3parts = json.load(fp)\n",
    "\n",
    "live_seeds = [int(key) for key in demo_2parts.keys()]\n",
    "demo_keys = demo_2parts.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17187623",
   "metadata": {},
   "source": [
    "## Compute live scores \n",
    "1. We compute live scores of the current state of the gripper wrt start frames of the part.\n",
    "2. The part is identified by traj_idx in the function\n",
    "3. demo_parts contains all the part information and the keyframes relating to each part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da6411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# Load Servoing Module\n",
    "from flow_control.servoing.module import ServoingModule\n",
    "control_config = dict(mode=\"pointcloud-abs-rotz\", threshold=0.40)\n",
    "servo_module = ServoingModule(recordings[0], control_config=control_config,\n",
    "                              start_paused=False)\n",
    "\n",
    "def compute_current_scores(playbacks, current_rgb, demo_parts, demo_good, traj_idx=0, live_seed=0):    \n",
    "    sim_errors = np.ones(len(playbacks)) # lower is better\n",
    "    mean_flows = np.zeros(len(playbacks))\n",
    "\n",
    "    for demo_seed in good_demonstrations:\n",
    "        start_idx = demo_parts[str(demo_seed)][traj_idx]['start']\n",
    "        demo_rgb =  playbacks[demo_seed][start_idx].cam.get_image()[0]\n",
    "        demo_mask =  playbacks[demo_seed].fg_masks[start_idx]\n",
    "        error, mean_flow = similarity_from_reprojection(current_rgb, demo_rgb, demo_mask)\n",
    "        sim_errors[demo_seed] = error\n",
    "        mean_flows[demo_seed] = mean_flow\n",
    "    errors_norm = normalize_errors(sim_errors, mean_flows, demo_good)\n",
    "    scores = 1 - errors_norm\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def similarity_from_reprojection(live_rgb, demo_rgb, demo_mask, return_images=False):\n",
    "    # evaluate the similarity via flow reprojection error\n",
    "    flow = servo_module.flow_module.step(demo_rgb, live_rgb)\n",
    "    warped = servo_module.flow_module.warp_image(live_rgb / 255.0, flow)\n",
    "    diff = (warped - (demo_rgb / 255.0))\n",
    "    error = np.linalg.norm((warped - (demo_rgb / 255.0)), axis=2) * demo_mask\n",
    "    error = error.sum() / demo_mask.sum()\n",
    "    mean_flow = np.linalg.norm(flow[demo_mask],axis=1).mean()\n",
    "    if return_images:\n",
    "        return error, mean_flow, flow, warped\n",
    "    return error, mean_flow\n",
    "\n",
    "\n",
    "def normalize_errors(errors, flows, demo_good):\n",
    "    errors_l = errors[demo_good]\n",
    "    mean_flows_l = flows[demo_good]\n",
    "    errors_norm = np.ones(errors.shape)\n",
    "    w = .5\n",
    "    errors_norm[demo_good] = np.mean((1*minmax_scale(errors_l), w*minmax_scale(mean_flows_l)),axis=0)/(1+w)\n",
    "    return errors_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03192a40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Arrange keypoint information for all parts in a easy to use data structure\n",
    "def split_keypoints(pb, demo_part, num_parts=2):\n",
    "    demo_keep = sorted(list(pb.keep_dict.keys()))\n",
    "    keep_all = copy.copy(pb.keep_dict)\n",
    "    keep_parts = {}\n",
    "    for p in demo_part:\n",
    "        if p[\"start\"] == 0:\n",
    "            p_start = -1\n",
    "        else:\n",
    "            p_start = p[\"start\"]\n",
    "\n",
    "        parts = []\n",
    "        for demo_index in demo_keep:\n",
    "            if p_start < demo_index and p[\"end\"] >= demo_index:\n",
    "                parts.append(demo_index)   \n",
    "\n",
    "        keep_parts[p[\"name\"]] = parts\n",
    "    \n",
    "    if num_parts == 2:        \n",
    "        # Need to also add the first frame of the 'insert' part to the 'locate' part\n",
    "        keep_parts['locate'].append(keep_parts['insert'][0])\n",
    "    elif num_parts == 3:\n",
    "        # Need to also add the first frame of the 'insert' part to the 'locate' part\n",
    "        keep_parts['grasp'].append(keep_parts['insert'][0])\n",
    "        \n",
    "    return keep_parts\n",
    "\n",
    "keypoint_info_2parts = {}\n",
    "keypoint_info_3parts = {}\n",
    "\n",
    "for demo_seed in good_demonstrations:\n",
    "    keypoint_info_2parts[demo_seed] = split_keypoints(playbacks[demo_seed], demo_2parts[str(demo_seed)])\n",
    "    keypoint_info_3parts[demo_seed] = split_keypoints(playbacks[demo_seed], demo_3parts[str(demo_seed)], num_parts=3)\n",
    "\n",
    "keypoint_info_3parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829c6bde",
   "metadata": {},
   "source": [
    "## Search for best trajectory \n",
    "\n",
    "For this experiment, we only consider the 'sum' and 'prod' scoring functions.\n",
    "\n",
    "The following function computes the cumulative scores starting at each part all the way to the goal state.\n",
    "\n",
    "For example:\n",
    "\n",
    "live_state ---- score_matrix_1 ---- score_matrix_2 ---- goal_state \n",
    "\n",
    "simplifies to \n",
    "\n",
    "live_scores ---- cscore[0] ---- cscore[1] ---- cscore[2]\n",
    "\n",
    "1. cscore[2] just contains the goal scores\n",
    "2. cscore[i] is an array of size n ** (num_parts - i)\n",
    "3. score_matrices = [score_matrix_1, score_matrix_2, and so on]\n",
    "4. Once the live scores are available, they can be used along with the corresponding cumulative score to find the best demonstration index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaed15c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cumulative scores staring from the goal state\n",
    "# score_matrices should contain all the computed score matrices in order from live state to goal state\n",
    "\n",
    "def get_cumulative_scores(scores_rear, score_matrices, score_fn='sum'):\n",
    "    # Start from goal state, add goal scores to the list\n",
    "    cumulative_scores = [scores_rear]    \n",
    "    \n",
    "    num_demos = scores_rear.shape[0]\n",
    "    \n",
    "    # Need to compute cumulative scores from the goal state. Need to reverse the order\n",
    "    score_matrices.reverse()\n",
    "    \n",
    "    # Compute cumulative scores at the start of each part by repeat and broadcast operations\n",
    "    for idx, sm in enumerate(score_matrices):\n",
    "        sm = sm.repeat(num_demos ** idx, axis=1)\n",
    "        if score_fn == 'sum':\n",
    "            new_scores = sm + cumulative_scores[-1]\n",
    "        elif score_fn == 'prod':\n",
    "            new_scores = sm * cumulative_scores[-1]\n",
    "        new_scores = new_scores.reshape(-1)\n",
    "        cumulative_scores.append(new_scores)\n",
    "    \n",
    "    # Need to reverse this list so that scores are arranged in the direction of traversal\n",
    "    # This will now be of the format [n ** 3, n**2, n] (3 part case) for n demonstrations\n",
    "    cumulative_scores.reverse()\n",
    "    \n",
    "    return cumulative_scores\n",
    "\n",
    "score_matrices_2parts = [score_matrix_2_part]\n",
    "score_matrices_3parts = [score_matrix_3_part_1, score_matrix_3_part_2]\n",
    "\n",
    "num_demos = score_matrix_2_part.shape[0]\n",
    "scores_rear = np.ones((num_demos))\n",
    "\n",
    "cumulative_scores_2_parts = {}\n",
    "cumulative_scores_2_parts['sum'] = get_cumulative_scores(scores_rear, score_matrices_2parts, score_fn='sum')\n",
    "cumulative_scores_2_parts['prod'] = get_cumulative_scores(scores_rear, score_matrices_2parts, score_fn='prod')\n",
    "\n",
    "cumulative_scores_3_parts = {}\n",
    "cumulative_scores_3_parts['sum'] = get_cumulative_scores(scores_rear, score_matrices_3parts, score_fn='sum')\n",
    "cumulative_scores_3_parts['prod'] = get_cumulative_scores(scores_rear, score_matrices_3parts, score_fn='prod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23348513",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([len(x) for x in cumulative_scores_2_parts['sum']])\n",
    "print([len(x) for x in cumulative_scores_3_parts['sum']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a452941",
   "metadata": {},
   "source": [
    "## Compute best demonstration index using live score and cumulative_scores\n",
    "\n",
    "1. 'score_front' is computed live\n",
    "2. 'cm_score' contains the cumulative score (flattened) at the corresponding part index\n",
    "3. 'factor' helps determine the correct index of the demonstration\n",
    "4. 'score_front' is repeated 'factor' times to enable combining it with the cumulative score.\n",
    "4. Then, an argmax operation helps find the correct index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd9b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_part(score_front, cm_score, factor, step_value=None, score_fn='sum'):\n",
    "    sf = score_front.repeat(factor)\n",
    "    if score_fn == 'sum':\n",
    "        temp = sf + cm_score\n",
    "    elif score_fn == 'prod':\n",
    "        temp = sf * cm_score\n",
    "    \n",
    "    return np.argmax(temp[0:factor * step_value]) // factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b59dd",
   "metadata": {},
   "source": [
    "## Evaluation Function \n",
    "We evaluate different combinations of experiments here:\n",
    "\n",
    "Pick-n-Place task with sum and prod combinations for a different number of shape-sorting demonstrations\n",
    "\n",
    "1. scores_front is pre-computed and stored (because this remains the same always)\n",
    "2. New scores at next stages are computed on the go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "from math import pi\n",
    "from flow_control.servoing.module import ServoingModule\n",
    "from gym_grasping.envs.robot_sim_env import RobotSimEnv\n",
    "from flow_control.runner import evaluate_control\n",
    "import ipdb\n",
    "import cv2\n",
    "\n",
    "\n",
    "selected_recordings = {}\n",
    "for task in ['pick_n_place']:\n",
    "    for score_fn in ['sum', 'prod']:\n",
    "        for steps in [1, 5, 10, 15, 20]:\n",
    "            selected_recordings[f'{task}_{score_fn}_{steps}'] = {}\n",
    "        \n",
    "def eval_cmb(playbacks, cumulative_scores, demo_good, live_seed, demo_parts, keypoint_info, step_val, score_fn, sf, num_parts=2):\n",
    "    \n",
    "    save_root = f'{data_dir}/multi_part_run/{num_parts}/{score_fn}/{step_val}'\n",
    "    cscores = cumulative_scores[score_fn]\n",
    "   \n",
    "    # Instantiate env\n",
    "    env = RobotSimEnv(task='shape_sorting', renderer=renderer, act_type='continuous',\n",
    "                      initial_pose='close', max_steps=500, control='absolute-full',\n",
    "                      img_size=(256, 256), param_randomize=(\"geom\",), seed=int(live_seed),\n",
    "                      task_info=dict(object_rot_range={\"rP\":pi/2.,\"rR\":pi/6.}[task_variant]))\n",
    "    \n",
    "    # Mapping part to index\n",
    "    traj_map = {0: 'locate', 1: 'insert'}\n",
    "        \n",
    "    save_dir = None\n",
    "    \n",
    "    # Total number of demonstrations that are used\n",
    "    num_demos = scores_rear.shape[0]\n",
    "    \n",
    "    for idx in range(2):        \n",
    "        state, _, _, _ = env.step(None)\n",
    "        \n",
    "        # Get the current gripper state\n",
    "        current_rgb = state['rgb_gripper']\n",
    "        \n",
    "        if sf is None:\n",
    "            if idx == 1:\n",
    "                scores_front = compute_current_scores(playbacks, current_rgb, demo_parts, demo_good, traj_idx=idx, live_seed=live_seed)\n",
    "#                 best_idx = 0\n",
    "            else:\n",
    "                print('Not possible to get here')\n",
    "        else:\n",
    "            \n",
    "        # Compute live scores wrt the first image of the current part under consideration\n",
    "#             scores_front = compute_current_scores(playbacks, current_rgb, demo_parts, demo_good, traj_idx=idx, live_seed=live_seed)\n",
    "\n",
    "            # Compute a trajectory, get the demonstration (part) index that maximizes the score\n",
    "            best_idx = get_best_part(sf, cscores[idx], num_demos ** (1 - idx), score_fn=score_fn, step_value=step_val)        \n",
    "        best_demo = recordings[best_idx]\n",
    "        \n",
    "        # Keypoints for the demonstration part    \n",
    "        kp_info = keypoint_info[best_idx]\n",
    "        kps = kp_info[traj_map[idx]]\n",
    "        \n",
    "        if idx == 0:\n",
    "            selected_recordings[f'{task}_{score_fn}_{step_val}'][live_seed] = [best_demo]\n",
    "        \n",
    "        if idx == 1:\n",
    "            save_dir = f\"{save_root}/run_pnp_{live_seed}_{best_idx}\"\n",
    "            folder_idx = 1\n",
    "            updated_dir = save_dir\n",
    "            while os.path.isdir(updated_dir):\n",
    "                updated_dir = f\"{save_dir}_{folder_idx}\"\n",
    "                folder_idx += 1\n",
    "            \n",
    "            save_dir = updated_dir\n",
    "            selected_recordings[f'{task}_{score_fn}_{step_val}'][live_seed].append(best_demo)\n",
    "            \n",
    "        servo_module = ServoingModule(best_demo, control_config=control_config,\n",
    "                                      start_paused=False, plot=False, plot_save_dir=None,\n",
    "                                      load='select', selected_kp=kps)\n",
    "        reward = 0\n",
    "        _, reward, _, info = evaluate_control(env, servo_module, max_steps=130, save_dir=save_dir,\n",
    "                                             initial_align=True if idx == 0 else False)\n",
    "        \n",
    "        sf = None\n",
    "        \n",
    "    del env\n",
    "    del servo_module\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fdc95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_front(seeds, demo_parts, demo_good):\n",
    "    scores_front = []\n",
    "    for idx, seed in enumerate(seeds):\n",
    "        # Instantiate env\n",
    "        env = RobotSimEnv(task='shape_sorting', renderer=renderer, act_type='continuous',\n",
    "                          initial_pose='close', max_steps=500, control='absolute-full',\n",
    "                          img_size=(256, 256), param_randomize=(\"geom\",), seed=int(seed),\n",
    "                          task_info=dict(object_rot_range={\"rP\":pi/2.,\"rR\":pi/6.}[task_variant]))\n",
    "        \n",
    "        state, _, _, _ = env.step(None)\n",
    "        \n",
    "        # Get the current gripper state\n",
    "        current_rgb = state['rgb_gripper']\n",
    "\n",
    "        # Compute live scores wrt the first image of the current part under consideration\n",
    "        sf = compute_current_scores(playbacks, current_rgb, demo_parts, demo_good, traj_idx=0, live_seed=seed)\n",
    "        \n",
    "        scores_front.append(sf)\n",
    "        \n",
    "        del env\n",
    "        \n",
    "    return scores_front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad37df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Servoing Rewards\n",
    "num_live_seeds = 20\n",
    "\n",
    "sel_recordings = {}\n",
    "seeds = range(100, 100 + num_live_seeds)\n",
    "\n",
    "scores_front_2parts = get_scores_front(seeds, demo_2parts, demo_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb297dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{root_dir}/scores_front_2parts.npy', scores_front_2parts, allow_pickle=True)\n",
    "# scores_front_2parts = np.load(f'{root_dir}/scores_front_2parts.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ad9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rewards = {}  \n",
    "\n",
    "for score_fn in ['sum', 'prod']:\n",
    "    for step_idx, step_val in enumerate([1, 5, 10, 15, 20]):\n",
    "        rewards = []\n",
    "        for live_idx, live_seed in enumerate(range(num_live_seeds)):\n",
    "            rew = eval_cmb(playbacks, cumulative_scores_2_parts, demo_good, live_seed, demo_2parts, keypoint_info_2parts, score_fn=score_fn, step_val=step_val, sf=scores_front_2parts[live_idx], num_parts=2)\n",
    "            rewards.append(rew)\n",
    "        all_rewards[f\"{score_fn}_{step_val}\"] = rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81783e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_uids = {'trapeze': 2, 'oval': 6}\n",
    "def filter_run(pb, uid):\n",
    "    return 1 if pb[-1].data['rew'] > 0 and np.atleast_1d(pb[-1].data['info'])[0]['object_selected'] == uid else 0\n",
    "new_rewards = {}\n",
    "for task in ['pick_n_place']:\n",
    "    for score_fn in ['sum', 'prod']:\n",
    "        for step_idx, step_val in enumerate([1, 5, 10, 15, 20]):\n",
    "            run_dir = f'{data_dir}/multi_task_run_1vsN/{task}/{score_fn}/{step_val}'\n",
    "            \n",
    "            rewards = []\n",
    "            for run in os.listdir(run_dir):            \n",
    "                pb = PlaybackEnvServo(os.path.join(run_dir, run))\n",
    "                rew = filter_run(pb, object_uids['trapeze'])\n",
    "                rewards.append(rew)\n",
    "            new_rewards[f\"{task}_{score_fn}_{step_val}\"] = rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c2fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in new_rewards:\n",
    "    print(key, np.mean(new_rewards[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a0842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "steps = [1, 5, 10, 15, 20]\n",
    "fig, ax = plt.subplots()\n",
    "# ax = plt.figure().gca()\n",
    "def format_fn(tick_val, tick_pos):\n",
    "    if int(tick_val) in steps:\n",
    "        return int(tick_val)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# A FuncFormatter is created automatically.\n",
    "# ax.xaxis.set_major_formatter(format_fn)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "for task in [\"pick_n_place\"]:\n",
    "    mean_rew = {}\n",
    "    for score_fn in ['sum', 'prod']:\n",
    "        rew = []\n",
    "        for step_idx, step_val in enumerate(steps):\n",
    "            key = f\"{task}_{score_fn}_{step_val}\"\n",
    "            rew.append(np.mean(new_rewards[key]))\n",
    "        mean_rew[score_fn] = rew\n",
    "        ax.plot(steps, rew, '.-', label=f'score_fn={score_fn}')\n",
    "ax.set_ylim(ymin=0)\n",
    "\n",
    "mean_rP, std_rP = 0.38, 0.19\n",
    "\n",
    "ax.plot([0, 20], [mean_rP, mean_rP], \"k--\")\n",
    "ax.axhspan(mean_rP - std_rP, mean_rP + std_rP, facecolor='gray', alpha=0.2)\n",
    "ax.legend()\n",
    "ax.set_title(\"Multi-Task Experiment: 1 'PNP' vs N 'SS'\")\n",
    "ax.set_xlabel(\"#Demonstrations\")\n",
    "ax.set_ylabel(\"Mean Rewards\")\n",
    "fig.savefig('multi_task.jpg', dpi=800)\n",
    "# ax.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe21a3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robot1",
   "language": "python",
   "name": "robot1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
