{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eac98bd",
   "metadata": {},
   "source": [
    "# Multi-Shape Live Selection\n",
    "\n",
    "To use this notebook, you already should have run the following notebooks:\n",
    "1. E2_0_Record_and_Segment.ipynb\n",
    "2. E2_1_Recombination_Selection.ipynb\n",
    "\n",
    "Summary:\n",
    "1. This notebook uses already computed scores stored as npz files\n",
    "2. For each part, compute scores at the front live (current_rgb vs first frame of the part)\n",
    "3. Compute full trajectory from current state to the goal state\n",
    "\n",
    "We compute rewards for the shapes: {'trapeze', 'oval'} using scoring functions {'sum', 'prod'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e64e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "import unittest\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "from gym_grasping.envs.robot_sim_env import RobotSimEnv\n",
    "from flow_control.demo.demo_episode_recorder import record_sim\n",
    "from flow_control.runner import evaluate_control\n",
    "from flow_control.servoing.module import ServoingModule\n",
    "from flow_control.servoing.playback_env_servo import PlaybackEnvServo\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, interact, Layout\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import getpass\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "experiment = \"multi_shape\"\n",
    "goal = \"multi_shape_goal\"\n",
    "renderer = 'debug'\n",
    "task_variant = 'rP'\n",
    "task = 'pick_n_place'\n",
    "\n",
    "def get_data_dir():\n",
    "    username = getpass.getuser()\n",
    "    if username == \"argusm\":\n",
    "        return \"/tmp/flow_experiments3\"\n",
    "    elif username == \"nayakab\":\n",
    "        return \"../tmp\"\n",
    "\n",
    "data_dir = get_data_dir()\n",
    "\n",
    "root_dir = os.path.join(data_dir, experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8950f0b7",
   "metadata": {},
   "source": [
    "## Load all Demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recordings(directory):\n",
    "    return sorted([os.path.join(directory, rec) for rec in os.listdir(directory) if os.path.isdir(os.path.join(directory, rec))])\n",
    "\n",
    "recordings = get_recordings(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72960233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the demonstration episodes\n",
    "playbacks = [PlaybackEnvServo(rec) for rec in recordings[:]]\n",
    "\n",
    "# Plot the demonstrations\n",
    "%matplotlib notebook\n",
    "fig, ax = plt.subplots(1,figsize=(8, 6))\n",
    "fig.suptitle(\"Demonstration Frames\")\n",
    "ax.set_axis_off()\n",
    "image_h = ax.imshow(playbacks[0].cam.get_image()[0])\n",
    "\n",
    "def update(demo_index, frame_index):\n",
    "    image = playbacks[demo_index][frame_index].cam.get_image()[0]\n",
    "    image_h.set_data(image)\n",
    "    fig.canvas.draw_idle()\n",
    "    print(\"wp_name:\", playbacks[demo_index][frame_index].get_info()[\"wp_name\"])\n",
    "    fg_mask = playbacks[demo_index].get_fg_mask()\n",
    "    if fg_mask is not None:\n",
    "        print(\"percent fg:\", np.mean(fg_mask)*100)\n",
    "    \n",
    "slider_w = widgets.IntSlider(min=0, max=len(playbacks)-1, step=1, value=0,\n",
    "                             layout=Layout(width='70%'))\n",
    "slider_i = widgets.IntSlider(min=0, max=200-1, step=1, value=0,\n",
    "                             layout=Layout(width='70%'))\n",
    "\n",
    "interact(update, demo_index=slider_w, frame_index=slider_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddef42cb",
   "metadata": {},
   "source": [
    "# Read scores (errors) from the stored files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e691f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_matrix = np.load(f\"{root_dir}/error_matrix.npz\")['arr_0']\n",
    "score_matrix = 1 - error_matrix\n",
    "\n",
    "# Errors wrt goal images\n",
    "scores_rear = {}\n",
    "shapes = ['trapeze', 'oval']\n",
    "for shape in shapes:\n",
    "    scores_rear[shape] = 1 - np.load(f\"{root_dir}/errors_rear_{shape}.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get good demonstrations and demonstration part information\n",
    "def filter_demo(pb):\n",
    "    return pb[-1].data['rew'] > 0 and np.mean(pb.get_fg_mask()) > 0.005\n",
    "\n",
    "demo_good = [filter_demo(pb) for pb in playbacks]\n",
    "good_demonstrations = np.where(demo_good)[0]\n",
    "\n",
    "good_demonstrations = [int(x) for x in good_demonstrations][0:38]\n",
    "live_seeds = good_demonstrations[0:39]\n",
    "print(good_demonstrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a2c1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load demo segmentation file\n",
    "demo_seg_file = f'{root_dir}/demo_parts_manual2.json'\n",
    "fp = open(demo_seg_file)\n",
    "demo_parts = json.load(fp)\n",
    "live_seeds = [int(key) for key in demo_parts.keys()]\n",
    "demo_keys = demo_parts.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17187623",
   "metadata": {},
   "source": [
    "## Compute live scores \n",
    "1. We compute live scores of the current state of the gripper wrt start frames of the part.\n",
    "2. The part is identified by traj_idx in the function\n",
    "3. demo_parts contains all the part information and the keyframes relating to each part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da6411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "from flow_control.servoing.module import ServoingModule\n",
    "\n",
    "# Servoing Module\n",
    "control_config = dict(mode=\"pointcloud-abs-rotz\", threshold=0.40)\n",
    "servo_module = ServoingModule(recordings[0], control_config=control_config,\n",
    "                              start_paused=False)\n",
    "\n",
    "\n",
    "def compute_current_scores(playbacks, current_rgb, demo_parts, demo_good, traj_idx=0, live_seed=0):    \n",
    "    sim_errors = np.ones(len(playbacks)) # lower is better\n",
    "    mean_flows = np.zeros(len(playbacks))\n",
    "\n",
    "    for demo_seed in good_demonstrations:\n",
    "        start_idx = demo_parts[str(demo_seed)][traj_idx]['start']\n",
    "        demo_rgb =  playbacks[demo_seed][start_idx].cam.get_image()[0]\n",
    "        demo_mask =  playbacks[demo_seed].fg_masks[start_idx]\n",
    "        error, mean_flow = similarity_from_reprojection(current_rgb, demo_rgb, demo_mask)\n",
    "        sim_errors[demo_seed] = error\n",
    "        mean_flows[demo_seed] = mean_flow\n",
    "    errors_norm = normalize_errors(sim_errors, mean_flows, demo_good)\n",
    "    scores = 1 - errors_norm\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def similarity_from_reprojection(live_rgb, demo_rgb, demo_mask, return_images=False):\n",
    "    # evaluate the similarity via flow reprojection error\n",
    "    flow = servo_module.flow_module.step(demo_rgb, live_rgb)\n",
    "    warped = servo_module.flow_module.warp_image(live_rgb / 255.0, flow)\n",
    "    diff = (warped - (demo_rgb / 255.0))\n",
    "    error = np.linalg.norm((warped - (demo_rgb / 255.0)), axis=2) * demo_mask\n",
    "    error = error.sum() / demo_mask.sum()\n",
    "    mean_flow = np.linalg.norm(flow[demo_mask],axis=1).mean()\n",
    "    if return_images:\n",
    "        return error, mean_flow, flow, warped\n",
    "    return error, mean_flow\n",
    "\n",
    "def normalize_errors(errors, flows, demo_good):\n",
    "    errors_l = errors[demo_good]\n",
    "    mean_flows_l = flows[demo_good]\n",
    "    errors_norm = np.ones(errors.shape)\n",
    "    w = .5\n",
    "    errors_norm[demo_good] = np.mean((1*minmax_scale(errors_l), w*minmax_scale(mean_flows_l)),axis=0)/(1+w)\n",
    "    return errors_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03192a40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Arrange keypoint information for all parts in a easy to use data structure\n",
    "\n",
    "def split_keypoints(pb, demo_part):\n",
    "    demo_keep = sorted(list(pb.keep_dict.keys()))\n",
    "    keep_all = copy.copy(pb.keep_dict)\n",
    "    keep_parts = {}\n",
    "    for p in demo_part:\n",
    "        if p[\"start\"] == 0:\n",
    "            p_start = -1\n",
    "        else:\n",
    "            p_start = p[\"start\"]\n",
    "\n",
    "        parts = []\n",
    "        for demo_index in demo_keep:\n",
    "            if p_start < demo_index and p[\"end\"] >= demo_index:\n",
    "                parts.append(demo_index)   \n",
    "\n",
    "        keep_parts[p[\"name\"]] = parts\n",
    "    keep_parts['locate'].append(keep_parts['insert'][0])\n",
    "    return keep_parts\n",
    "\n",
    "keypoint_info = {}\n",
    "for demo_seed in good_demonstrations:\n",
    "    keypoint_info[demo_seed] = split_keypoints(playbacks[demo_seed], demo_parts[str(demo_seed)])\n",
    "\n",
    "keypoint_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829c6bde",
   "metadata": {},
   "source": [
    "## Search for best trajectory \n",
    "\n",
    "For this experiment, we only consider the 'sum' and 'prod' scoring functions.\n",
    "\n",
    "The following function computes the cumulative scores starting at each part all the way to the goal state.\n",
    "\n",
    "For example:\n",
    "\n",
    "live_state ---- score_matrix_1 ---- score_matrix_2 ---- goal_state \n",
    "\n",
    "simplifies to \n",
    "\n",
    "live_scores ---- cscore[0] ---- cscore[1] ---- cscore[2]\n",
    "\n",
    "1. cscore[2] just contains the goal scores\n",
    "2. cscore[i] is an array of size n ** (num_parts - i)\n",
    "3. score_matrices = [score_matrix_1, score_matrix_2, and so on]\n",
    "4. Once the live scores are available, they can be used along with the corresponding cumulative score to find the best demonstration index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d737295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cumulative scores staring from the goal state\n",
    "# score_matrices should contain all the computed score matrices in order from live state to goal state\n",
    "\n",
    "def get_cumulative_scores(scores_rear, score_matrices, score_fn='sum'):\n",
    "    # Start from goal state, add goal scores to the list\n",
    "    cumulative_scores = [scores_rear]    \n",
    "    \n",
    "    num_demos = scores_rear.shape[0]\n",
    "    \n",
    "    # Need to compute cumulative scores from the goal state. Need to reverse the order\n",
    "    score_matrices.reverse()\n",
    "    \n",
    "    # Compute cumulative scores at the start of each part by repeat and broadcast operations\n",
    "    for idx, sm in enumerate(score_matrices):\n",
    "        sm = sm.repeat(num_demos ** idx, axis=1)\n",
    "        if score_fn == 'sum':\n",
    "            new_scores = sm + cumulative_scores[-1]\n",
    "        elif score_fn == 'prod':\n",
    "            new_scores = sm * cumulative_scores[-1]\n",
    "        new_scores = new_scores.reshape(-1)\n",
    "        cumulative_scores.append(new_scores)\n",
    "    \n",
    "    # Need to reverse this list so that scores are arranged in the direction of traversal\n",
    "    # This will now be of the format [n ** 3, n**2, n] (3 part case) for n demonstrations\n",
    "    cumulative_scores.reverse()\n",
    "    \n",
    "    return cumulative_scores\n",
    "\n",
    "score_matrices = [score_matrix]\n",
    "\n",
    "cumulative_scores = {}\n",
    "\n",
    "for shape in shapes:\n",
    "    for score_fn in ['sum', 'prod']:\n",
    "        cumulative_scores[f'{shape}_{score_fn}'] = get_cumulative_scores(scores_rear[shape][:, 0], score_matrices, score_fn=score_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0713fc96",
   "metadata": {},
   "source": [
    "## Compute best demonstration index using live score and cumulative_scores\n",
    "\n",
    "1. 'score_front' is computed live\n",
    "2. 'cm_score' contains the cumulative score (flattened) at the corresponding part index\n",
    "3. 'factor' helps determine the correct index of the demonstration\n",
    "4. 'score_front' is repeated 'factor' times to enable combining it with the cumulative score.\n",
    "4. Then, an argmax operation helps find the correct index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1bf1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_part(score_front, cm_score, factor, score_fn='sum'):\n",
    "    sf = score_front.repeat(factor)\n",
    "    if score_fn == 'sum':\n",
    "        best_idx = np.argmax(sf + cm_score) // factor\n",
    "    elif score_fn == 'prod':\n",
    "        best_idx = np.argmax(sf * cm_score) // factor\n",
    "    \n",
    "    return best_idx  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b59dd",
   "metadata": {},
   "source": [
    "## Evaluation Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a366182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "from math import pi\n",
    "from flow_control.servoing.module import ServoingModule\n",
    "from gym_grasping.envs.robot_sim_env import RobotSimEnv\n",
    "from flow_control.runner import evaluate_control\n",
    "import ipdb\n",
    "import cv2\n",
    "\n",
    "\n",
    "selected_recordings = {}\n",
    "def eval_cmb(playbacks, cumulative_scores, demo_good, live_seed, demo_parts, keypoint_info, shape, score_fn):\n",
    "    \n",
    "    save_root = f'{data_dir}/multi_shape_run_single/{shape}/{score_fn}'\n",
    "    cscores = cumulative_scores[f'{shape}_{score_fn}']\n",
    "   \n",
    "    # Instantiate env\n",
    "    env = RobotSimEnv(task='recombination', renderer=renderer, act_type='continuous',\n",
    "                      initial_pose='close', max_steps=500, control='absolute-full',\n",
    "                      img_size=(256, 256), param_randomize=(\"geom\",),\n",
    "                      param_info={'object_selected': shape, 'task_selected': task},\n",
    "                      task_info=dict(object_rot_range={\"rP\":pi/2.,\"rR\":pi/6.}[task_variant]),\n",
    "                      seed=int(live_seed))\n",
    "    \n",
    "    # Mapping part to index\n",
    "    traj_map = {0: 'locate', 1: 'insert'}\n",
    "    \n",
    "    save_dir = None\n",
    "    \n",
    "    # Total number of demonstrations that are used\n",
    "    num_demos = scores_rear[shape].shape[0]\n",
    "    \n",
    "    for idx in range(2):        \n",
    "        state, _, _, _ = env.step(None)\n",
    "        \n",
    "        # Get the current gripper state\n",
    "        current_rgb = state['rgb_gripper']\n",
    "        \n",
    "        # Compute live scores wrt the first image of the current part under consideration\n",
    "        scores_front = compute_current_scores(playbacks, current_rgb, demo_parts, demo_good, traj_idx=idx, live_seed=live_seed)\n",
    "        \n",
    "        # Compute a trajectory, get the demonstration (part) index that maximizes the score\n",
    "        best_idx = get_best_part(scores_front, cscores[idx], num_demos ** (1 - idx), score_fn=score_fn)        \n",
    "        best_demo = recordings[best_idx]\n",
    "        \n",
    "        # Keypoints for the demonstration part    \n",
    "        kp_info = keypoint_info[best_idx]\n",
    "        kps = kp_info[traj_map[idx]]\n",
    "        \n",
    "        if idx == 0:\n",
    "            selected_recordings[live_seed] = [best_demo]\n",
    "        \n",
    "        if idx == 1:\n",
    "            save_dir = f\"{save_root}/run_pnp_{live_seed}_{best_idx}\"\n",
    "            folder_idx = 1\n",
    "            updated_dir = save_dir\n",
    "            while os.path.isdir(updated_dir):\n",
    "                updated_dir = f\"{save_dir}_{folder_idx}\"\n",
    "                folder_idx += 1\n",
    "            \n",
    "            save_dir = updated_dir\n",
    "            selected_recordings[live_seed].append(best_demo)\n",
    "            \n",
    "        servo_module = ServoingModule(best_demo, control_config=control_config,\n",
    "                                      start_paused=False, plot=False, plot_save_dir=None,\n",
    "                                      load='select', selected_kp=kps)\n",
    "        _, reward, _, info = evaluate_control(env, servo_module, max_steps=130, save_dir=save_dir,\n",
    "                                             initial_align=True if idx == 0 else False)\n",
    "        \n",
    "    del env\n",
    "    del servo_module\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad37df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Servoing Rewards\n",
    "num_live_seeds = 20\n",
    "all_rewards = {}\n",
    "\n",
    "for shape in shapes:\n",
    "    for score_fn in ['sum', 'prod']:\n",
    "        rewards = []\n",
    "        for live_idx, live_seed in enumerate(range(num_live_seeds)):\n",
    "            rew = eval_cmb(playbacks, cumulative_scores, demo_good, live_seed, demo_parts, keypoint_info, shape, score_fn=score_fn)\n",
    "            rewards.append(rew)\n",
    "        all_rewards[f\"{shape}_{score_fn}\"] = rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121aa707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "\n",
    "object_uids = {'trapeze': 2, 'oval': 6}\n",
    "def filter_run(pb, uid):\n",
    "    return 1 if pb[-1].data['rew'] > 0 and np.atleast_1d(pb[-1].data['info'])[0]['object_selected'] == uid else 0\n",
    "\n",
    "new_rewards = {}\n",
    "\n",
    "# Get filtered rewards from runs\n",
    "for shape in shapes:\n",
    "    for score_fn in ['sum', 'prod']:\n",
    "        run_dir = f'{data_dir}/multi_shape_run/{shape}/{score_fn}'\n",
    "        rewards = []\n",
    "        for run in os.listdir(run_dir):            \n",
    "            pb = PlaybackEnvServo(os.path.join(run_dir, run))\n",
    "            rew = filter_run(pb, object_uids[shape])\n",
    "            rewards.append(rew)\n",
    "        new_rewards[f\"{shape}_{score_fn}\"] = rewards\n",
    "\n",
    "for score_fn in ['sum', 'prod']:\n",
    "    for shape in shapes:\n",
    "        key = f\"{shape}_{score_fn}\"\n",
    "        print(f\"{key}: {np.mean(single_rewards[key])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68806f9a",
   "metadata": {},
   "source": [
    "## Computing cumulative scores for the single shape cases\n",
    "1. Restrict access to demonstrations of other shapes\n",
    "2. Set cumulative score values to 0, to prevent the demonstration from being selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ccfdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgood = {}\n",
    "dgood['trapeze'] = demo_good.copy()\n",
    "dgood['oval'] = demo_good.copy()\n",
    "dgood\n",
    "\n",
    "dgood['trapeze'][0:20] = [False for i in range(20)]\n",
    "dgood['oval'][20:] = [False for i in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb171490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "cscores_single = copy.deepcopy(cumulative_scores)\n",
    "\n",
    "for score_fn in ['sum', 'prod']:\n",
    "    for idx in range(2):\n",
    "        num_entries = cscores_single[f'trapeze_{score_fn}'][idx].shape[0]\n",
    "        cscores_single[f'trapeze_{score_fn}'][idx][0:num_entries // 2] *= 0\n",
    "        \n",
    "for score_fn in ['sum', 'prod']:\n",
    "    for idx in range(2):\n",
    "        num_entries = cscores_single[f'oval_{score_fn}'][idx].shape[0]\n",
    "        cscores_single[f'oval_{score_fn}'][idx][num_entries // 2:] *= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc6ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Servoing Rewards\n",
    "num_live_seeds = 20\n",
    "all_rewards = {}\n",
    "\n",
    "for shape in shapes:   \n",
    "    for score_fn in ['sum', 'prod']:\n",
    "        rewards = []\n",
    "        for live_idx, live_seed in enumerate(range(num_live_seeds)):\n",
    "            rew = eval_cmb(playbacks, cscores_single, dgood[shape], live_seed, demo_parts, keypoint_info, shape, score_fn=score_fn)\n",
    "            rewards.append(rew)\n",
    "        all_rewards[f\"{shape}_{score_fn}\"] = rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8e0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results - Single Shape case\n",
    "\n",
    "object_uids = {'trapeze': 2, 'oval': 6}\n",
    "def filter_run(pb, uid):\n",
    "    return 1 if pb[-1].data['rew'] > 0 and np.atleast_1d(pb[-1].data['info'])[0]['object_selected'] == uid else 0\n",
    "\n",
    "single_rewards = {}\n",
    "\n",
    "# Get filtered rewards from runs\n",
    "for shape in shapes:\n",
    "    for score_fn in ['sum', 'prod']:\n",
    "        run_dir = f'{data_dir}/multi_shape_run_single/{shape}/{score_fn}'\n",
    "        rewards = []\n",
    "        for run in os.listdir(run_dir):            \n",
    "            pb = PlaybackEnvServo(os.path.join(run_dir, run))\n",
    "            rew = filter_run(pb, object_uids[shape])\n",
    "            rewards.append(rew)\n",
    "        single_rewards[f\"{shape}_{score_fn}\"] = rewards\n",
    "\n",
    "for score_fn in ['sum', 'prod']:\n",
    "    for shape in shapes:\n",
    "        key = f\"{shape}_{score_fn}\"\n",
    "        print(f\"{key}: {np.mean(single_rewards[key])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81783e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_uids = {'trapeze': 2, 'oval': 6}\n",
    "def filter_run(pb, uid):\n",
    "    return 1 if pb[-1].data['rew'] > 0 and np.atleast_1d(pb[-1].data['info'])[0]['object_selected'] == uid else 0\n",
    "new_rewards = {}\n",
    "for shape in shapes:\n",
    "    for score_fn in ['sum', 'prod']:\n",
    "        run_dir = f'{data_dir}/multi_shape_run_old_fn/{shape}/{score_fn}'\n",
    "        rewards = []\n",
    "        for run in os.listdir(run_dir):            \n",
    "            pb = PlaybackEnvServo(os.path.join(run_dir, run))\n",
    "            rew = filter_run(pb, object_uids[shape])\n",
    "            rewards.append(rew)\n",
    "        new_rewards[f\"{shape}_{score_fn}\"] = rewards"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robot1",
   "language": "python",
   "name": "robot1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
