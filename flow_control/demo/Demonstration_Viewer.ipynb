{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Demonstration Viewer\n",
    "\n",
    "This notebook is for viewing and processing demonstrations so that they can be used for servoing. This has two main components. The first is subsampling the trajectory to obtain a set of keysteps for which we want to do servoing. It is not necessary to servo to all intermediate states, this increases the speed of servoing dramatically.\n",
    "\n",
    "The second is computing a foregreound segmentation mask. This is needed in order to be able to focus on the objects of interested and to avoid being confounded by various other objects.\n",
    "\n",
    "Script Arguments:\n",
    "\n",
    "    recording: the directory in which the recording is located. Should include:\n",
    "        `frame_000000.npz`\n",
    "        `camera_info.npz`\n",
    "   \n",
    "Returns:\n",
    "    `servo_keep.json`\n",
    "    `servo_mask.json`\n",
    "    \n",
    "\n",
    "# Setup\n",
    "\n",
    "First we start by loading the demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "def is_notebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True  # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False  # Probably standard Python interpreter\n",
    "\n",
    "interactive = is_notebook()  # becomes overwritten\n",
    "if interactive:\n",
    "    get_ipython().run_line_magic('matplotlib', 'notebook')\n",
    "    from ipywidgets import widgets, interact, Layout\n",
    "    import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from robot_io.envs.playback_env import PlaybackEnv\n",
    "from robot_io.recorder.simple_recorder import unprocess_seg\n",
    "\n",
    "if interactive:    \n",
    "    # set parameters here\n",
    "    #recording = \"../tmp_test/pick_n_place/\"\n",
    "    #recording = \"../tmp_test/shape_sorting_trapeze_rN/\"\n",
    "    recording = \"/home/argusm/CLUSTER/robot_recordings/flow/sick_wtt/16-51-30\"\n",
    "else:\n",
    "    # expect commandline input\n",
    "    import sys\n",
    "    if len(sys.argv) != 3:\n",
    "        print(\"Usage: Demonstration_Viewer.py <episode_dir>\")\n",
    "    recording = sys.argv[1]\n",
    "\n",
    "if not os.path.isdir(recording):\n",
    "    ValueError(f\"Recording directory not found: {recording}\")\n",
    "\n",
    "segment_conf_fn = os.path.join(recording, \"segment_conf.json\")\n",
    "keep_fn = os.path.join(recording, f\"servo_keep.json\")\n",
    "mask_fn = os.path.join(recording, f\"servo_mask.npz\")\n",
    "\n",
    "try:\n",
    "    with open(segment_conf_fn, \"r\") as f_obj:\n",
    "        orig_seg_conf = json.load(f_obj)\n",
    "        if type(orig_seg_conf[\"objects\"]) == list:\n",
    "            orig_seg_conf[\"objects\"] = orig_seg_conf[\"objects\"][0]\n",
    "        seg_conf = copy.deepcopy(orig_seg_conf)\n",
    "except FileNotFoundError:\n",
    "    seg_conf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = PlaybackEnv(recording).to_list()\n",
    "video_recording = np.array([renv.cam.get_image()[0] for renv in rec])\n",
    "actions = np.array([renv.get_action()[\"motion\"] for renv in rec], dtype=object)\n",
    "tcp_pos = np.array([renv.robot.get_tcp_pos() for renv in rec])\n",
    "tcp_orn = np.array([renv.robot.get_tcp_orn() for renv in rec])\n",
    "gripper_width = np.array([renv.robot.gripper.width() for renv in rec])\n",
    "\n",
    "if actions.ndim == 2 and actions.shape[1] == 3:\n",
    "    gripper_actions = np.array(actions[:, 2], dtype=float)\n",
    "else:\n",
    "    gripper_actions = np.array(actions[:, -1], dtype=float)\n",
    "\n",
    "assert gripper_width.ndim == 1\n",
    "gripper_width = np.array(gripper_width, dtype=float)\n",
    "percent_invalid = np.sum(np.isnan(gripper_width))/len(gripper_width)\n",
    "if percent_invalid > .1:\n",
    "    logging.warning(\"gripper positions are not valid\")\n",
    "    gripper_width_valid = False\n",
    "else:\n",
    "    gripper_width_valid = True\n",
    "\n",
    "\n",
    "masks_sim_l = []\n",
    "move_anchors = []\n",
    "wp_names = []\n",
    "for rec_el in rec:\n",
    "    rec_info = rec_el.data[\"info\"].item()\n",
    "    \n",
    "    if \"seg_mask\" in rec_info:\n",
    "        tmp = unprocess_seg(rec_info[\"seg_mask\"])[0]\n",
    "        masks_sim_l.append(tmp)\n",
    "    else:\n",
    "        masks_sim_l.append(None)\n",
    "    \n",
    "    if \"move_anchor\" in rec_info:\n",
    "        move_anchors.append(rec_info[\"move_anchor\"])\n",
    "    else:\n",
    "        move_anchors.append(None)\n",
    "    \n",
    "    if \"wp_name\" in rec_info:\n",
    "        wp_names.append(rec_info[\"wp_name\"])\n",
    "    else:\n",
    "        wp_names.append(\"\")\n",
    "\n",
    "masks_sim = np.array(masks_sim_l)\n",
    "if np.all(masks_sim == None):\n",
    "    masks_sim = None\n",
    "\n",
    "num_frames = len(rec)\n",
    "max_frame = num_frames-1\n",
    "\n",
    "print(f\"loaded segmentation masks {np.sum([s is not None for s in masks_sim_l])}/{num_frames}\" )\n",
    "print(f\"loaded move_anchors {np.sum([a is not None for a in move_anchors])}/{num_frames}\" )\n",
    "print(f\"loaded waypoint names {np.sum([wp !='' for wp in wp_names])}/{num_frames}\")\n",
    "    \n",
    "print(\"loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Compute Keep Steps \n",
    "\n",
    "Decide which frames to keep, this information is saved as a dictionary whos keys are the frame index.\n",
    "\n",
    "There are several possible sources of information to use when deciding which frames to keep.\n",
    "\n",
    "1. The waypoint names. If these are provided they show when a motion segment ends.\n",
    "2. Gripper action and state. Segment by the state of the gripper, also keep only those where gripper is stable.\n",
    "3. TCP motion. Find those frames where movement is minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use actions here instead of state position recordings as these\n",
    "# are more direct and reliable, but in general try to use states\n",
    "# as these are less suceptible to problems\n",
    "gripper_change_steps = np.where(np.diff(gripper_actions))[0].tolist()\n",
    "\n",
    "# divide sequence into steps, defined by gripper action\n",
    "segment_steps = np.zeros(num_frames)\n",
    "segment_steps[np.array(gripper_change_steps)+1] = 1\n",
    "segment_steps = np.cumsum(segment_steps).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recording == \"/home/argusm/CLUSTER/robot_recordings/flow/sick_wtt/16-51-30\":\n",
    "    keep_manual = {580:dict(name=\"manual-1\"), 699:dict(name=\"manual-2\")}\n",
    "else:\n",
    "    keep_manual = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo_trajectory_utils import get_demo_continous \n",
    "from demo_trajectory_utils import get_keep_from_wpnames, get_keep_from_gripper, get_keep_from_motion\n",
    "from demo_trajectory_utils import filter_by_move_anchors, filter_by_motions, check_names_grip\n",
    "from demo_trajectory_utils import set_trajectory_actions\n",
    "from demo_trajectory_utils import get_rel_motion, get_servo_anchors\n",
    "\n",
    "\n",
    "# module reloading for when updating demo_trajectory_utils functions\n",
    "from importlib import reload\n",
    "import demo_trajectory_utils\n",
    "reload(demo_trajectory_utils)\n",
    "from demo_trajectory_utils import set_trajectory_actions\n",
    "\n",
    "trajectory_debug_plots = False\n",
    "\n",
    "is_continous = get_demo_continous(tcp_pos)\n",
    "keep_wpnames = get_keep_from_wpnames(wp_names)\n",
    "keep_edge = {0: dict(name=\"demo_start\"), int(max_frame):dict(name=\"demo_end\")}\n",
    "keep_motion = {}\n",
    "keep_cmb = copy.copy(keep_edge)\n",
    "\n",
    "if keep_wpnames:\n",
    "    logging.info(\"Trajectory segmentation method: waypoint-names\")\n",
    "    # if all our waypoints have names, we can use these to segment\n",
    "    # the trajectory into individual steps.\n",
    "    check_names_grip(wp_names, gripper_change_steps)\n",
    "    keep_gripper = get_keep_from_gripper(gripper_actions)\n",
    "    if move_anchors:\n",
    "        filter_rel = [a == \"rel\" for a in move_anchors]\n",
    "        #filter_by_move_anchors(keep_wpnames, wp_names, filter_rel)\n",
    "    keep_cmb.update(keep_wpnames)\n",
    "    keep_cmb.update(keep_gripper)\n",
    "    motion_threshold = 0.001\n",
    "\n",
    "elif not is_continous:\n",
    "    logging.info(\"Trajectory segmentation method: discrete-demo\")\n",
    "    # if we have a hand-crafted recording, which includes only steps for\n",
    "    # servoing\n",
    "    keep_all = list(range(len(tcp_pos)))\n",
    "    keep_cmb.update(keep_all)\n",
    "    keep_cmb.update(keep_gripper)\n",
    "    motion_threshold = 0.001\n",
    "else:\n",
    "    logging.info(\"Trajectory segmentation method: motion-cues\")\n",
    "    # this case is a bit more complicated, we can use heuristics like low velocity\n",
    "    # to extract segment our trajectory.\n",
    "    keep_motion  = get_keep_from_motion(tcp_pos)\n",
    "    keep_gripper = get_keep_from_gripper(gripper_actions)\n",
    "    \n",
    "    # int(k) for json\n",
    "    keep_motion = dict([(int(k), dict(name=f\"motion-{i}\")) for i, k in enumerate(keep_motion)])\n",
    "    keep_cmb.update(keep_motion)\n",
    "    keep_cmb.update(keep_gripper)\n",
    "    motion_threshold = 0.02\n",
    "\n",
    "keep_cmb = {k: keep_cmb[k] for k in sorted(keep_cmb)}\n",
    "\n",
    "# postprocess keep frames    \n",
    "filter_by_motions(keep_cmb, tcp_pos, tcp_orn, gripper_actions, threshold=motion_threshold)\n",
    "\n",
    "# after filtering do manual overrides\n",
    "keep_cmb.update(keep_manual)\n",
    "keep_cmb = {k: keep_cmb[k] for k in sorted(keep_cmb)}\n",
    "\n",
    "# also sets grip_dist\n",
    "servo_anchors = get_servo_anchors(move_anchors)\n",
    "\n",
    "if keep_wpnames:\n",
    "    for k in keep_cmb:\n",
    "        if servo_anchors[k] == -1:\n",
    "            keep_cmb[k][\"skip\"] = True\n",
    "        else:\n",
    "            keep_cmb[k][\"skip\"] = False\n",
    "else:\n",
    "    for k in keep_cmb:\n",
    "        keep_cmb[k][\"skip\"] = False\n",
    "\n",
    "if \"sick_wtt\" in recording:\n",
    "    grp_o_df = -1\n",
    "else:\n",
    "    grp_o_df = 0\n",
    "set_trajectory_actions(keep_cmb, segment_steps, tcp_pos, tcp_orn, gripper_actions, grip_open_default=grp_o_df)\n",
    "\n",
    "for k, v in keep_cmb.items():\n",
    "    if v[\"grip_dist\"] >= 2:\n",
    "        keep_cmb[k][\"skip\"] = True\n",
    "    else:\n",
    "        keep_cmb[k][\"skip\"] = False\n",
    "\n",
    "print()\n",
    "for k,v in keep_cmb.items():\n",
    "    print(f\"{k}\".ljust(5),f\"{v['name']}\".ljust(15),\n",
    "          f\"grip_dist={v['grip_dist']}\".ljust(15), f\"skip={int(v['skip'])}\",f\"pre={len(v['pre'])}\")\n",
    "    \n",
    "# save keep frames\n",
    "with open(keep_fn, 'w') as outfile:\n",
    "    json.dump(keep_cmb, outfile)\n",
    "print(\"Saved to\", keep_fn)\n",
    "\n",
    "#plot_motion_error()\n",
    "\n",
    "#TOD(max): redo fitler_keep in a iterative greedy manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep2plot(keep):\n",
    "    arr = np.zeros(len(actions))\n",
    "    arr[list(keep.keys())] = 1\n",
    "    return arr\n",
    "\n",
    "if interactive:\n",
    "    fig, (ax, ax2) = plt.subplots(2, 1)\n",
    "    fig.suptitle(\"Keep frame Components\")\n",
    "    line = ax.imshow(video_recording[0])\n",
    "    ax.set_axis_off()\n",
    "    #ax2.plot(gripper_width*10, label=\"grip raw\")\n",
    "    ax2.plot((gripper_actions+1)/2,\"--\", label=\"gripper action\")\n",
    "    ax2.plot(segment_steps/10, label=\"steps\")\n",
    "    if keep_wpnames:\n",
    "        ax2.plot(keep2plot(keep_wpnames), label=\"keep_wpnames\")\n",
    "    if keep_motion:\n",
    "        ax2.plot(keep2plot(keep_motion), label=\"keep_motion\")\n",
    "    ax2.plot(keep2plot(keep_gripper), label=\"keep_gripper\")\n",
    "    ax2.plot(keep2plot(keep_edge), label=\"keep_edge\")\n",
    "    \n",
    "    if servo_anchors:\n",
    "        ax2.plot([a == -1 for a in servo_anchors], \"--\", label=\"rel\")\n",
    "    \n",
    "    ax2.set_ylabel(\"value\")\n",
    "    ax2.set_xlabel(\"frame number\")\n",
    "    vline = ax2.axvline(x=2, color=\"k\")\n",
    "    ax2.legend()\n",
    "\n",
    "    def update(w):\n",
    "        if wp_names:\n",
    "            print(\"wp_name:\",wp_names[w])\n",
    "        if w in keep_cmb:\n",
    "            print(keep_cmb[w])\n",
    "            print(\"pos:\", tcp_pos[w],\"orn:\", tcp_orn[w])\n",
    "        vline.set_data([w, w], [0, 1])\n",
    "        line.set_data(video_recording[w])\n",
    "        fig.canvas.draw_idle()\n",
    "    slider_w = widgets.IntSlider(min=0, max=max_frame, step=1, value=0,\n",
    "                                 layout=Layout(width='70%'))\n",
    "    interact(update, w=slider_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 TCP Stationary Filter\n",
    "\n",
    "There are to options here. The demonstration is recorded in a sparse way, this indicates that every frame should be kept, or the demonstration is recorded in a dense way, meaning that we need to figure out which frames we want to keep.\n",
    "\n",
    "In the case of dense demonstrations, a good heuristic to use is to use transitions in which there is slow robot motion indicates motion to a stable position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajectory_plots import plot_tcp_stationary\n",
    "\n",
    "if interactive and trajectory_debug_plots:\n",
    "    plot_tcp_stationary(tcp_pos, video_recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show when the gripping is done, depending on gripper motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajectory_plots import plot_gripper_stable \n",
    "if interactive and gripper_width_valid and trajectory_debug_plots:\n",
    "    plot_gripper_stable(gripper_width, gripper_actions, video_recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. C. Verify keep frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep2plot2(keep):\n",
    "    arr = np.zeros(len(actions))\n",
    "    for k,v in keep.items():\n",
    "        if v[\"grip_dist\"] < 2:\n",
    "            arr[k] = 1.0\n",
    "        else:\n",
    "            arr[k] = 0.8\n",
    "        if \"anchor\" in v and v[\"anchor\"] == \"rel\":\n",
    "            arr[k] = 0.1\n",
    "        #arr[k] = 1.0 - min(v[\"grip_dist\"], 5) * 0.1\n",
    "    return arr\n",
    "\n",
    "if interactive:\n",
    "    fig, (ax, ax2) = plt.subplots(2, 1)\n",
    "    fig.suptitle(\"Verify keep frames\")\n",
    "    line = ax.imshow(video_recording[0])\n",
    "    ax.set_axis_off()\n",
    "    ax2.plot(gripper_width*10, label=\"grip raw\")\n",
    "    ax2.plot(segment_steps/10, label=\"steps\")\n",
    "    ax2.plot(keep2plot2(keep_cmb), label=\"keep\")\n",
    "    #ax2.plot((gripper_actions+1)/2, label=\"gripper action\")\n",
    "    if servo_anchors:\n",
    "        ax2.plot([a == -1 for a in servo_anchors], \"--\", label=\"rel\")\n",
    "\n",
    "    ax2.set_ylabel(\"value\")\n",
    "    ax2.set_xlabel(\"frame number\")\n",
    "    vline = ax2.axvline(x=2, color=\"k\")\n",
    "    ax2.legend()\n",
    "\n",
    "    def update(w):\n",
    "        if wp_names:\n",
    "            print(\"frame name:\", wp_names[w])\n",
    "        vline.set_data([w, w], [0, 1])\n",
    "        line.set_data(video_recording[w])\n",
    "        fig.canvas.draw_idle()\n",
    "        if w in keep_cmb:\n",
    "            print(keep_cmb[w])\n",
    "            print()\n",
    "    slider_w = widgets.IntSlider(min=0, max=max_frame, step=1, value=0,\n",
    "                                 layout=Layout(width='70%'))\n",
    "    interact(update, w=slider_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compute Mask from Color Images\n",
    "\n",
    "Mask out the foreground object so that foreground specific flow can be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_conf_manual = (\"sick_wtt\" in segment_conf_fn)\n",
    "\n",
    "if \"sick_wtt/16-51-30\" in segment_conf_fn:\n",
    "    blue_threshold = 0.77\n",
    "    conf_objects = dict(\n",
    "    blue_block=[{'name': 'color', 'color': [0, 0, 1], 'threshold': blue_threshold},\n",
    "                {'name': 'center'}],\n",
    "    white_block=[{'name': 'color', 'color': \"keep_black\", 'threshold': .38},\n",
    "                {'name': 'center'}])\n",
    "    conf_sequence = (\"blue_block\", \"white_block\", \"white_block\")\n",
    "else:\n",
    "    blue_threshold = 0.65\n",
    "    conf_objects = dict(\n",
    "    blue_block=[{'name': 'color', 'color': [0, 0, 1], 'threshold': blue_threshold},\n",
    "                {'name': 'center'}])\n",
    "    conf_sequence = (\"blue_block\", \"blue_block\", \"blue_block\")\n",
    "\n",
    "    \n",
    "seg_conf_m = dict(objects=conf_objects, sequence=conf_sequence)\n",
    "\n",
    "if seg_conf_manual:\n",
    "    if seg_conf is not None:\n",
    "        print(f\"Overloading color segmentation config with local values:\\n{segment_conf_fn}\")\n",
    "    seg_conf = seg_conf_m\n",
    "    orig_seg_conf = copy.deepcopy(seg_conf_m)\n",
    "    \n",
    "if seg_conf is None:\n",
    "    print(f\"Skipping color segmentation, config file not found:\\n{segment_conf_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Compute Mask from Color Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "from scipy import ndimage\n",
    "from demo_segment_util import mask_color, erode_mask, label_mask, mask_center\n",
    "\n",
    "# create a segmentation mask\n",
    "def get_mask(frame, step_conf, depth=None):\n",
    "    \"\"\"\n",
    "    create segmentation mask for single frame\n",
    "    Args:\n",
    "        frame: input frame w x h x 3 [0,255] array\n",
    "        i: index of frame, for indexing parameters\n",
    "        threshold: threshold for color\n",
    "        \n",
    "    Returns:\n",
    "        mask: binary numpy array, with True == keep\n",
    "    \"\"\"\n",
    "    threshold = step_conf[0][\"threshold\"]    \n",
    "    image = frame.copy()\n",
    "    \n",
    "    for seg_option in step_conf:\n",
    "        name = seg_option[\"name\"]\n",
    "        \n",
    "        if name == \"color\":\n",
    "            color_choice = seg_option[\"color\"]\n",
    "            mask = mask_color(image, color_choice=color_choice, threshold=threshold)\n",
    "            \n",
    "        elif name == \"erode\":\n",
    "            mask = erode_mask(mask)\n",
    "            \n",
    "        elif name == \"height\":\n",
    "            raise NotImplementedError\n",
    "            depth2 = transform_depth(depth, np.linalg.inv(T_tcp_cam))\n",
    "            mask2 = get_mask_depth(depth2, 600, 1550)\n",
    "            mask[mask2] = True\n",
    "    \n",
    "        elif name == \"labels\":\n",
    "            raise NotImplementedError\n",
    "            mask = ndimage.morphology.binary_closing(mask, iterations=4)\n",
    "            mask = label_mask(mask, i)\n",
    "    \n",
    "        elif name == \"imgheight\":\n",
    "            height_val = seg_option[\"height\"]\n",
    "            mask[:height_val, :] = False\n",
    "            \n",
    "        elif name == \"center\":\n",
    "            mask = mask_center(mask)\n",
    "            \n",
    "    return mask\n",
    "\n",
    "def get_cur_mask(i):\n",
    "    # mask according to current fg object\n",
    "    cur_step = segment_steps[i]\n",
    "    cur_obj = seg_conf[\"sequence\"][cur_step]\n",
    "    step_conf = seg_conf[\"objects\"][cur_obj]\n",
    "    mask = get_mask(video_recording[i], step_conf)\n",
    "    return mask\n",
    "\n",
    "# Plot\n",
    "if seg_conf and interactive:\n",
    "    print(\"Colored stuff is keept (mask==True)\")\n",
    "    print(\"gripper_change_steps:\", gripper_change_steps)\n",
    "    print(\"segments: \", len(seg_conf))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    line = ax.imshow(video_recording[0])\n",
    "    ax.set_axis_off()\n",
    "    prev_step = 0\n",
    "    def update(i, t):\n",
    "        cur_step = segment_steps[i]\n",
    "        cur_obj = seg_conf[\"sequence\"][cur_step]\n",
    "        global prev_step\n",
    "        if cur_step != prev_step:\n",
    "            # don't change order here, without double checking\n",
    "            saved_t = seg_conf[\"objects\"][cur_obj][0][\"threshold\"]\n",
    "            print(f\"switching step {prev_step} -> {cur_step}, loading t={saved_t}\")\n",
    "            prev_step = cur_step\n",
    "            slider_t.value = saved_t*100\n",
    "        else:\n",
    "            seg_conf[\"objects\"][cur_obj][0][\"threshold\"] = t/100\n",
    "            \n",
    "        mask = get_cur_mask(i)\n",
    "        image = video_recording[i].copy()\n",
    "        image[np.logical_not(mask)] = 255, 255, 255\n",
    "        line.set_data(image)\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "    slider_i = widgets.IntSlider(min=0, max=max_frame, step=1, value=0,\n",
    "                                 layout=Layout(width='70%'))\n",
    "    first_obj = seg_conf[\"sequence\"][0]\n",
    "    slider_t = widgets.IntSlider(min=0, max=100, step=1, value=seg_conf[\"objects\"][first_obj][0][\"threshold\"]*100,\n",
    "                                 layout=Layout(width='70%'))\n",
    "    interact(update, i=slider_i, t=slider_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display changes to thresholds\n",
    "if seg_conf:\n",
    "    for name in seg_conf[\"objects\"]:\n",
    "        print(\"name:\", name)\n",
    "        c = seg_conf[\"objects\"][name][0][\"color\"]\n",
    "        t = seg_conf[\"objects\"][name][0][\"threshold\"]\n",
    "        t_i = orig_seg_conf[\"objects\"][name][0][\"threshold\"]\n",
    "        \n",
    "        #, seg_option_orig in zip(seg_conf[\"objects\"], orig_seg_conf[\"objects\"]):\n",
    "        if t != t_i:\n",
    "            print(\"c={}, t={} / was t'={}\".format(c, t, t_i))\n",
    "        else:\n",
    "            print(\"c={}, t={}\".format(c, t))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if seg_conf:\n",
    "    switch_frame = gripper_change_steps\n",
    "    print(\"switching at:\", switch_frame)\n",
    "    if orig_seg_conf is None:\n",
    "        orig_seg_conf = seg_conf\n",
    "        \n",
    "    obj_ids = {}\n",
    "    obj_ids_list = []\n",
    "    for i, obj in enumerate(seg_conf[\"objects\"]):\n",
    "        obj_ids[obj] = i+1\n",
    "        obj_ids_list.append(i+1)\n",
    "        print(f\"{obj} -> {i+1}\")\n",
    "\n",
    "    fg_obj = []\n",
    "    masks_list = []\n",
    "    for i in tqdm(range(len(video_recording))):\n",
    "        # get foreground object\n",
    "        cur_step = segment_steps[i]\n",
    "        cur_obj = seg_conf[\"sequence\"][cur_step]\n",
    "        fg_obj.append(obj_ids[cur_obj])\n",
    "\n",
    "        m_masks = []\n",
    "        for obj_name in seg_conf[\"objects\"]:\n",
    "            mask = get_mask(video_recording[i], seg_conf[\"objects\"][obj_name])\n",
    "            m_masks.append(mask)\n",
    "\n",
    "        overlapp = np.sum(m_masks, axis=0) > 1\n",
    "        if np.any(overlapp):\n",
    "            print(f\"WARNING: There is overlapp at {i}\")\n",
    "        masks_list.append(m_masks)\n",
    "\n",
    "    fg_obj = np.array(fg_obj)\n",
    "    assert fg_obj.ndim == 1\n",
    "\n",
    "    masks_list = np.array(masks_list)\n",
    "    masks_list = masks_list.transpose(1, 0, 2, 3).astype(np.uint8)\n",
    "    obj_ids_arr = np.array(obj_ids_list).reshape(-1, 1, 1, 1)\n",
    "    masks_list = obj_ids_arr*masks_list\n",
    "    masks_list = masks_list.sum(axis=0)\n",
    "    \n",
    "    np.savez_compressed(mask_fn, mask=masks_list, fg=fg_obj)\n",
    "    print(\"Saved to\", mask_fn)\n",
    "    \n",
    "    servo_anchors = fg_obj.tolist()\n",
    "\n",
    "    if seg_conf != orig_seg_conf:\n",
    "        print(\"Warning using new segmentation config values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 B. Check Masks from Color with Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if seg_conf and masks_sim is not None:\n",
    "    for i in range(num_frames):\n",
    "        image = video_recording[i].copy()\n",
    "        mask = masks_list[i] == fg_obj[i]\n",
    "        # mask segmentation mask(gt) with fg mask (computed)\n",
    "        ma = np.ma.array(masks_sim[i], mask=np.logical_not(mask))\n",
    "        ma_unique = np.unique(ma, return_counts=True)\n",
    "        # unique is sorted by size, pick the biggest\n",
    "        idx_largest = np.where(ma_unique[0])[-1][0]\n",
    "        seg_id, mask_count = ma_unique[0][idx_largest], ma_unique[1][idx_largest]\n",
    "        seg_count = np.sum(masks_sim[i] == seg_id)\n",
    "        # test how much we segmented / how much there is\n",
    "        score = mask_count / seg_count\n",
    "        assert score > .9\n",
    "    print(\"Segmentation test passed.\")\n",
    "else:\n",
    "    print(\"No comparison possible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Compute Masks from Simulation\n",
    "\n",
    "This cell extracts foreground masks from simulation recordings. It does this by looking at the recordings info variables, where a anchor object UID can be specified. This is usually done by the task policy.\n",
    "\n",
    "The move_anchor is the object with which we are moving relative to, this is most often but not always the object of interest or the foreground object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if masks_sim is not None and servo_anchors and not seg_conf:\n",
    "    fg_obj_sim = servo_anchors\n",
    "    np.savez_compressed(mask_fn, mask=masks_sim, fg=fg_obj_sim)\n",
    "    print(\"Saved to\", mask_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify\n",
    "if masks_sim is not None and servo_anchors and interactive:\n",
    "    fig, ax = plt.subplots(1)\n",
    "    handle = ax.imshow(video_recording[0])\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    def update(i):\n",
    "        image = video_recording[i].copy()\n",
    "        \n",
    "        # this is the code used by the seroving module, so don't change.\n",
    "        mask = masks_sim[i] == fg_obj_sim[i]\n",
    "        \n",
    "        print(round(np.mean(mask)*100), \"% fg, mask shape\", mask.shape)\n",
    "        image[np.logical_not(mask)] = 255, 255, 255\n",
    "        handle.set_data(image)\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "    slider_i2 = widgets.IntSlider(min=0, max=max_frame, step=1, value=0,\n",
    "                                 layout=Layout(width='70%'))\n",
    "    interact(update, i=slider_i2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if  interactive:\n",
    "    for k, v in keep_cmb.items():\n",
    "        if v[\"skip\"] == False:\n",
    "            print(k,)\n",
    "    tmp = np.load(mask_fn)\n",
    "    \n",
    "    fig, ax = plt.subplots(1)\n",
    "    handle = ax.imshow(tmp[\"mask\"][0] == tmp[\"fg\"][0])\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    def update(i):\n",
    "        image = video_recording[i].copy()\n",
    "        mask = tmp[\"mask\"][i] == tmp[\"fg\"][i]\n",
    "        print(round(np.mean(mask)*100), \"% fg, mask shape\", mask.shape)\n",
    "        image[np.logical_not(mask)] = 255, 255, 255\n",
    "        handle.set_data(image)\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "    slider_i2 = widgets.IntSlider(min=0, max=max_frame, step=1, value=0,\n",
    "                                 layout=Layout(width='70%'))\n",
    "    interact(update, i=slider_i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.load(mask_fn)\n",
    "for k, info in keep_cmb.items():\n",
    "    mask = tmp[\"mask\"][k] == tmp[\"fg\"][k]\n",
    "    if servo_anchors[k] == -1:\n",
    "        pixels_segmented = np.sum(mask==True)\n",
    "        if pixels_segmented > 0:\n",
    "            logging.warning(\"Keyframe %s: segmentation given for relative motion.\", k)\n",
    "    else:\n",
    "        percent_segmented = np.mean(mask==True)\n",
    "        if percent_segmented < .01:\n",
    "            logging.warning(\"Keyframe %s: low fraction of image segmented for keyframe %s\", k, round(percent_segmented*100))\n",
    "    \n",
    "print(f\"Checking {mask_fn} passed.\")                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Masking based on Depth"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#episode_data = np.load(recording_fn)\n",
    "#keys = list(episode_data.keys())\n",
    "#camera_calibration = dict(width=640,height=480,\n",
    "#                     fx = 617.8902587890625, fy=617.8903198242188, \n",
    "#                     ppx=315.20367431640625, ppy=245.70614624023438 )\n",
    "#\n",
    "#T_tcp_cam = np.array([\n",
    "#    [0.99987185, -0.00306941, -0.01571176, 0.00169436],\n",
    "#    [-0.00515523, 0.86743151, -0.49752989, 0.11860651],\n",
    "#    [0.015156,    0.49754713,  0.86730453, -0.18967231],\n",
    "#    [0., 0., 0., 1.]])\n",
    "#\n",
    "#depth = episode_data[\"depth_imgs\"]\n",
    "#depth_scale = 8000\n",
    "#i = 200\n",
    "#print(\"loaded.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#from demon_segment_util import transform_depth\n",
    "#\n",
    "#depth_flat = transform_depth(depth[i], np.linalg.inv(T_tcp_cam))\n",
    "#fig, (ax, ax2) = plt.subplots(1, 2)\n",
    "#line = ax.imshow(depth_flat)\n",
    "#ax2.plot(np.sort(depth[i].flatten()))\n",
    "#ax2.plot(np.sort(depth_flat.flatten()))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#def get_mask_depth(frame, l, h):\n",
    "#    mask = np.logical_or(frame < l/depth_scale, frame > h/depth_scale)\n",
    "#    mask = np.logical_not(mask)\n",
    "#    return mask\n",
    "#\n",
    "#def erode_mask(mask):\n",
    "#    return mask\n",
    "#    mask = ndimage.binary_closing(mask, iterations=5)\n",
    "#    mask = ndimage.morphology.binary_erosion(mask, iterations=10)\n",
    "#    return mask\n",
    "#\n",
    "#\n",
    "#x = np.linspace(0, 2*np.pi)\n",
    "#fig, ax = plt.subplots(1)\n",
    "#line = ax.imshow(video_recording[0])\n",
    "#\n",
    "#def update(w,l,h):\n",
    "#    depth2 = transform_depth(depth[w], np.linalg.inv(T_tcp_cam))\n",
    "#    mask = get_mask_depth(depth2, l, h)\n",
    "#    mask = erode_mask(mask)\n",
    "#    mask = np.logical_not(mask)\n",
    "#    display_image = video_recording[w].copy()\n",
    "#    display_image[mask] = 0\n",
    "#    line.set_data(display_image)\n",
    "#    fig.canvas.draw_idle()\n",
    "#    \n",
    "#depth_min, depth_max = int(depth.min()*depth_scale), int(depth.max()*depth_scale)\n",
    "#slider_w = widgets.IntSlider(min=0, max=max_frame, step=1, value=205,\n",
    "#                             layout=Layout(width='70%'))\n",
    "#slider_l = widgets.IntSlider(min=depth_min, max=depth_max, step=1, value=1560,\n",
    "#                             layout=Layout(width='70%'))\n",
    "#slider_h = widgets.IntSlider(min=depth_min, max=depth_max, step=1, value=1650,\n",
    "#                             layout=Layout(width='70%'))\n",
    "#\n",
    "#interact(update, w=slider_w, l=slider_l, h=slider_h)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# next steps: anneal the edge, and run connected component algorithm.\n",
    "#from scipy import ndimage\n",
    "#\n",
    "#w = slider_w.value\n",
    "#l = slider_l.value\n",
    "#h = slider_h.value\n",
    "#print(\"w={w}, l={l}, h={h}\".format(w=w, l=l, h=h))\n",
    "#\n",
    "#depth2 = transform_depth(depth[w], np.linalg.inv(T_tcp_cam))\n",
    "#mask_s = get_mask_depth(depth2, l, h)\n",
    "#mask_s = erode_mask(mask_s.copy())\n",
    "#mask_s = np.logical_not(mask_s)\n",
    "#display_image = video_recording[w].copy()\n",
    "#display_image[mask_s] = 0\n",
    "#\n",
    "#fig, ax = plt.subplots(1)\n",
    "#line = ax.imshow(display_image)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#threshold_low = slider_l.value\n",
    "#threshold_high = slider_h.value\n",
    "#\n",
    "#masks = np.zeros(video_recording.shape[:3], dtype=bool)\n",
    "#\n",
    "#for i in range(len(video_recording)):\n",
    "#    mask = get_mask_depth(depth[i], threshold_low, threshold_high)\n",
    "#    mask = erode_mask(mask)\n",
    "#    masks[i] = mask\n",
    "#\n",
    "#print(np.mean(masks)*100, \"percent of pixels fg\")\n",
    "#mask_fn = recording_fn.replace(\".npz\", \"_mask.npz\")\n",
    "#np.savez_compressed(mask_fn, mask=masks)\n",
    "#print(\"Saved to\", mask_fn)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#fig, ax = plt.subplots(1, 1)\n",
    "#line = ax.imshow(masks[25])\n",
    "#ax.set_axis_off()\n",
    "#\n",
    "#def update(i):\n",
    "#    image = video_recording[i].copy()\n",
    "#    mask = masks[i]\n",
    "#    image[mask] = 255, 255, 255\n",
    "#    line.set_data(image)\n",
    "#    fig.canvas.draw_idle()\n",
    "#    \n",
    "#slider_i2 = widgets.IntSlider(min=0, max=max_frame, step=1, value=200,\n",
    "#                             layout=Layout(width='70%'))\n",
    "#\n",
    "#interact(update, i=slider_i2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
