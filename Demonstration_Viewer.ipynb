{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration View\n",
    "\n",
    "View a demonstration by sliding through the frames.\n",
    "This also plots the z height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from ipywidgets import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "folder_format = \"lukas\"\n",
    "#recording = \"stack_recordings/episode_118\"\n",
    "#recording = \"/media/kuka/Seagate Expansion Drive/kuka_recordings/flow/stacking_sim\"\n",
    "#recording, episode_num = \"/media/kuka/Seagate Expansion Drive/kuka_recordings/flow/shape_insert\", 10\n",
    "#recording, episode_num = \"/home/argusm/CLUSTER/kuka_recordings/flow/shape_insert\", 10\n",
    "\n",
    "recording, episode_num = \"/home/argusm/CLUSTER/robot_recordings/flow/lego\", 3\n",
    "demonstration_type = \"grasp_insert\"\n",
    "keep_frames_method = \"dense\"\n",
    "movement_threshold = None  #1e-5\n",
    "gripper_close_steps = 10\n",
    "segment_colors = [(1,0,0), (0,0,1)]\n",
    "segment_thresholds = [.75,.60]\n",
    "segment_height = False\n",
    "segment_labels = False\n",
    "\n",
    "#recording, episode_num = \"/home/argusm/CLUSTER/robot_recordings/flow/wheel\", 5\n",
    "#demonstration_type = \"grasp_insert\"\n",
    "#keep_frames_method = \"dense\"\n",
    "#movement_threshold = None  #1e-5\n",
    "#gripper_close_steps = 30\n",
    "#segment_colors = [\"bw\", \"bw\", \"bw\"]\n",
    "#segment_thresholds = [.50, .50, .50]\n",
    "#segment_labels = (2, -1, -1)\n",
    "#segment_height = (False, True, True)\n",
    "\n",
    "\n",
    "if folder_format == 'max':\n",
    "    state_recording_fn = \"./{}/episode_{}.npz\".format(recording, episode_num)\n",
    "    state_recording = np.load(state_recording_fn)\n",
    "    ee_positions = state_recording[\"ee_positions\"]\n",
    "    flow_recording_fn = \"./{}/episode_{}_img.npz\".format(recording, episode_num)\n",
    "    flow_recording = np.load(flow_recording_fn)[\"img\"]\n",
    "    gr_positions = state_recording[\"gripper_states\"]\n",
    "else:\n",
    "    state_recording_fn = \"{}/episode_{}.npz\".format(recording, episode_num)\n",
    "    flow_recording_fn = \"{}/episode_{}.npz\".format(recording, episode_num)\n",
    "    state_recording = np.load(state_recording_fn)[\"robot_state_full\"]\n",
    "    actions = np.load(state_recording_fn)[\"actions\"]\n",
    "    ee_positions = state_recording[:,:3]\n",
    "    flow_recording = np.load(flow_recording_fn)[\"rgb_unscaled\"]\n",
    "    try:\n",
    "        seg_masks = np.load(flow_recording_fn)[\"seg_masks\"]\n",
    "    except (KeyError,ValueError):\n",
    "        seg_masks = None\n",
    "\n",
    "print(\"loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep Frames\n",
    "\n",
    "decide which frames to keep, saved as per-frame boolean array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use actions here instead of state position recordings as these\n",
    "# are more reliable\n",
    "gr_actions = actions[:, -1]\n",
    "num_frames = flow_recording.shape[0]-1\n",
    "keysteps = np.where(np.diff(gr_actions))[0]+1\n",
    "# divide sequence into steps, defined by gripper action\n",
    "segment_steps = np.cumsum(np.abs(np.diff(gr_actions)/2)).astype(int)\n",
    "segment_steps = np.concatenate((segment_steps, segment_steps[-1:]))\n",
    "\n",
    "\n",
    "print(\"keysteps\", keysteps)\n",
    "print(\"demonstration type:\", demonstration_type)\n",
    "if demonstration_type == \"grasp_insert\":\n",
    "    assert(len(keysteps) == 2)\n",
    "    grip_step = keysteps[0]\n",
    "    open_step = keysteps[1]\n",
    "    print(\"grip_step\", grip_step, g2txt(grip_step))\n",
    "    print(\"open_step\", open_step, g2txt(open_step))\n",
    "else:\n",
    "    raise ValueError\n",
    "    \n",
    "def g2txt(step):\n",
    "    return [\"close\",\"open\"][gr_actions[step].astype(int)]\n",
    "\n",
    "if keep_frames_method == \"dense\":\n",
    "    keep_array = np.ones(gr_actions.shape, dtype=bool)\n",
    "    keep_array[grip_step:grip_step+gripper_close_steps] = False\n",
    "elif keep_frames_method == \"sparse\":\n",
    "    keep_frames = np.array((80, 81, 105, 110, 120,  204, 206))\n",
    "    print(\"1 is open, -1 is closed\")\n",
    "    print(\"gripper positions\", gr_actions[keep_frames])\n",
    "    keep_array = np.zeros(gr_actions.shape, dtype=bool)\n",
    "    keep_array[keep_frames] = True\n",
    "elif keep_frames_method == \"all\":\n",
    "    keep_array = np.ones(gr_actions.shape, dtype=bool)\n",
    "else:\n",
    "    raise ValueError\n",
    "\n",
    "if movement_threshold is not None:\n",
    "    # append a entry here as diff has of n-1\n",
    "    movement = np.linalg.norm(np.diff(ee_positions[:,0:3], axis=0, append=((0,0,0),)), axis=1)\n",
    "    movement_mask = movement < movement_threshold    \n",
    "    keep_array[movement_mask] = False    \n",
    "\n",
    "\n",
    "\n",
    "keep_fn = flow_recording_fn.replace(\".npz\", \"_keep.npz\")\n",
    "np.savez(keep_fn, keep=keep_array)\n",
    "print(\"Saved to\", keep_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify keep frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = flow_recording.shape[0]-1\n",
    "x = np.linspace(0, 2 * np.pi)\n",
    "fig, (ax, ax2) = plt.subplots(2, 1)\n",
    "line = ax.imshow(flow_recording[0])\n",
    "ax.set_axis_off()\n",
    "#ax2.plot(ee_positions[:,0],label=\"x\")\n",
    "#ax2.plot(ee_positions[:,1],label=\"y\")\n",
    "ax2.plot(state_recording[:, -2], label=\"grip raw\")\n",
    "ax2.plot(segment_steps/10,label=\"steps\")\n",
    "ax2.plot(keep_array, label=\"keep\")\n",
    "ax2.plot((gr_actions+1)/2, label=\"gripper action\")\n",
    "#ax2.plot(movement,label=\"movement\")\n",
    "ax2.set_ylabel(\"value\")\n",
    "ax2.set_xlabel(\"frame number\")\n",
    "vline = ax2.axvline(x=2, color=\"k\")\n",
    "ax2.legend()\n",
    "def update(w):\n",
    "    vline.set_data([w,w], [0,1])\n",
    "    line.set_data(flow_recording[w])\n",
    "    fig.canvas.draw_idle()\n",
    "slider_w = widgets.IntSlider(min=0, max=num_frames, step=1, value=0,\n",
    "                             layout=Layout(width='70%'))\n",
    "interact(update, w=slider_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask View\n",
    "\n",
    "Mask out the foreground object so that foreground specific flow can be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "\n",
    "def erode_mask(mask):\n",
    "    mask = ndimage.binary_closing(mask, iterations=2)\n",
    "    mask = ndimage.morphology.binary_erosion(mask, iterations=4)\n",
    "    return mask\n",
    "\n",
    "def label_mask(mask, i):\n",
    "    labels, num = measure.label(np.logical_not(mask), background=0, return_num=True)\n",
    "    if segment_colors:\n",
    "        cur_label = segment_labels[segment_steps[i]]\n",
    "    if cur_label == -1:\n",
    "        cur_label = num\n",
    "    \n",
    "    mask = labels == cur_label\n",
    "    return mask\n",
    "\n",
    "def get_mask(frame, i=None, threshold=0):\n",
    "    if seg_masks is not None:\n",
    "        mask = (seg_masks[i] == 2) if color_index == 0 else (seg_masks[i] == 3)\n",
    "        return mask\n",
    "    \n",
    "    step = segment_steps[i]\n",
    "    image = frame.copy()\n",
    "    color_choice = segment_colors[step]\n",
    "    if color_choice == \"bw\":\n",
    "        tmp =  np.linalg.norm(image/255,axis=2) \n",
    "    else:\n",
    "        color_choice = np.array(color_index)    \n",
    "        tmp = np.linalg.norm(image * color_choice,axis=2) / np.linalg.norm(image,axis=2) \n",
    "    mask = tmp > threshold\n",
    "    \n",
    "    mask = erode_mask(mask)\n",
    "    \n",
    "    if segment_height and segment_height[step]:\n",
    "        depth2 = transform_depth(depth[i], np.linalg.inv(T_tcp_cam))\n",
    "        mask2 = get_mask_depth(depth2, 600, 1550)\n",
    "        mask[mask2] = True\n",
    "        \n",
    "    if segment_labels and segment_labels[step]:\n",
    "        mask = ndimage.morphology.binary_closing(mask, iterations=4)\n",
    "        mask = label_mask(mask, i)\n",
    "        #line.set_data(labels)\n",
    "        \n",
    "    return mask\n",
    "\n",
    "print(\"The colored stuff - mask==True\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "line = ax.imshow(flow_recording[25])\n",
    "ax.set_axis_off()\n",
    "def update(i,t):\n",
    "    image = flow_recording[i].copy()\n",
    "    mask = get_mask(image, i=i, threshold=t/100)\n",
    "    image[np.logical_not(mask)] = 255,255,255\n",
    "    line.set_data(image)\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "slider_i = widgets.IntSlider(min=0, max=num_frames, step=1, value=grip_step,\n",
    "                             layout=Layout(width='70%'))\n",
    "\n",
    "slider_t = widgets.IntSlider(min=0, max=100, step=1, value=segment_thresholds[0]*100,\n",
    "                             layout=Layout(width='70%'))\n",
    "\n",
    "\n",
    "interact(update, i=slider_i, t=slider_t)\n",
    "\n",
    "print(\"len\",len(segment_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = np.zeros(flow_recording.shape[:3], dtype=bool)\n",
    "switch_frame = grip_step\n",
    "print(\"switching at:\", switch_frame)\n",
    "for c,t in zip(segment_colors, segment_thresholds):\n",
    "    print(c,t)\n",
    "print()\n",
    "\n",
    "for i in range(len(flow_recording)):\n",
    "    j = int(i > switch_frame)\n",
    "    color_index = segment_colors[j]\n",
    "    threshold = segment_thresholds[j]\n",
    "    mask = get_mask(flow_recording[i], i, threshold)\n",
    "    masks[i] = mask\n",
    "\n",
    "print(np.mean(masks) * 100, \"percent of pixels fg\")\n",
    "if folder_format == 'max':\n",
    "    mask_fn = flow_recording_fn.replace(\"_img.npz\", \"_mask.npz\")\n",
    "else:\n",
    "    mask_fn = flow_recording_fn.replace(\".npz\", \"_mask.npz\")\n",
    "np.savez(mask_fn, mask=masks)\n",
    "print(\"Saved to\", mask_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify masking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "line = ax.imshow(masks[25])\n",
    "ax.set_axis_off()\n",
    "\n",
    "def update(i):\n",
    "    image = flow_recording[i].copy()\n",
    "    mask = masks[i]\n",
    "    image[np.logical_not(mask)] = 255, 255, 255\n",
    "    line.set_data(image)\n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "slider_i2 = widgets.IntSlider(min=0, max=num_frames, step=1, value=25,\n",
    "                             layout=Layout(width='70%'))\n",
    "\n",
    "interact(update, i=slider_i2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking based on Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_data = np.load(state_recording_fn)\n",
    "#keys = list(episode_data.keys())\n",
    "camera_calibration = dict(width=640,height=480,\n",
    "                     fx = 617.8902587890625, fy=617.8903198242188, \n",
    "                     ppx=315.20367431640625, ppy=245.70614624023438 )\n",
    "\n",
    "\n",
    "T_tcp_cam = np.array([\n",
    "    [0.99987185, -0.00306941, -0.01571176, 0.00169436],\n",
    "    [-0.00515523, 0.86743151, -0.49752989, 0.11860651],\n",
    "    [0.015156,    0.49754713,  0.86730453, -0.18967231],\n",
    "    [0., 0., 0., 1.]])\n",
    "\n",
    "depth = episode_data[\"depth_imgs\"]\n",
    "depth_scale = 8000\n",
    "\n",
    "i = 200\n",
    "print(\"loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_depth(depth_image, transformation):\n",
    "    \"\"\"\n",
    "    Transform a depth image into a point cloud with one point for each\n",
    "    pixel in the image, using the camera transform for a camera\n",
    "    centred at cx, cy with field of view fx, fy.\n",
    "\n",
    "    depth is a 2-D ndarray with shape (rows, cols) containing\n",
    "    depths from 1 to 254 inclusive. The result is a 3-D array with\n",
    "    shape (rows, cols, 3). Pixels with invalid depth in the input have\n",
    "    NaN for the z-coordinate in the result.\n",
    "    \"\"\"\n",
    "    assert(camera_calibration)\n",
    "    assert(camera_calibration[\"width\"] == depth_image.shape[1])\n",
    "    assert(camera_calibration[\"height\"] == depth_image.shape[0])\n",
    "\n",
    "    C_X = camera_calibration[\"ppx\"]\n",
    "    C_Y = camera_calibration[\"ppy\"]\n",
    "    F_X = camera_calibration[\"fx\"]\n",
    "    F_Y = camera_calibration[\"fy\"]\n",
    "    \n",
    "    rows, cols = depth_image.shape\n",
    "    c, r = np.meshgrid(np.arange(cols), np.arange(rows), sparse=True)\n",
    "    \n",
    "    z = depth_image\n",
    "    x = z * (c - C_X) / F_X\n",
    "    y = z * (r - C_Y) / F_Y\n",
    "    o = np.ones(z.shape)\n",
    "    \n",
    "    tmp = np.stack((x, y, z, o), axis=2)\n",
    "    tmp2 = tmp @ transformation\n",
    "    tmp3 = tmp2[:, :, :3] / tmp2[:, :, 3, np.newaxis]\n",
    "    return tmp3[:,:,2]\n",
    "\n",
    "\n",
    "depth_flat = transform_depth(depth[i], np.linalg.inv(T_tcp_cam))\n",
    "fig, (ax,ax2) = plt.subplots(1,2)\n",
    "line = ax.imshow(depth_flat)\n",
    "ax2.plot(np.sort(depth[i].flatten()))\n",
    "ax2.plot(np.sort(depth_flat.flatten()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_depth(frame, l, h):\n",
    "    mask = np.logical_or(frame < l/depth_scale, frame > h/depth_scale)\n",
    "    mask = np.logical_not(mask)\n",
    "    return mask\n",
    "\n",
    "def erode_mask(mask):\n",
    "    return mask\n",
    "    mask = ndimage.binary_closing(mask, iterations=5)\n",
    "    mask = ndimage.morphology.binary_erosion(mask, iterations=10)\n",
    "    return mask\n",
    "\n",
    "x = np.linspace(0, 2 * np.pi)\n",
    "fig, ax = plt.subplots(1)\n",
    "line = ax.imshow(flow_recording[0])\n",
    "\n",
    "def update(w,l,h):\n",
    "    depth2 = transform_depth(depth[w], np.linalg.inv(T_tcp_cam))\n",
    "    mask = get_mask_depth(depth2, l, h)\n",
    "    mask = erode_mask(mask)\n",
    "    mask = np.logical_not(mask)\n",
    "    display_image = flow_recording[w].copy()\n",
    "    display_image[mask] = 0\n",
    "    line.set_data(display_image)\n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "depth_min, depth_max = int(depth.min()*depth_scale), int(depth.max()*depth_scale)\n",
    "slider_w = widgets.IntSlider(min=0,max=num_frames,step=1,value=205,\n",
    "                             layout=Layout(width='70%'))\n",
    "slider_l = widgets.IntSlider(min=depth_min,max=depth_max,step=1,value=1560,\n",
    "                             layout=Layout(width='70%'))\n",
    "slider_h = widgets.IntSlider(min=depth_min,max=depth_max,step=1,value=1650,\n",
    "                             layout=Layout(width='70%'))\n",
    "\n",
    "interact(update,w=slider_w,l=slider_l,h=slider_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next steps: anneal the edge, and run connected component algorithm.\n",
    "from scipy import ndimage\n",
    "\n",
    "w = slider_w.value\n",
    "l = slider_l.value\n",
    "h = slider_h.value\n",
    "print(\"w={w}, l={l}, h={h}\".format(w=w,l=l,h=h))\n",
    "\n",
    "depth2 = transform_depth(depth[w], np.linalg.inv(T_tcp_cam))\n",
    "mask_s = get_mask_depth(depth2, l, h)\n",
    "mask_s = erode_mask(mask_s.copy())\n",
    "mask_s = np.logical_not(mask_s)\n",
    "display_image = flow_recording[w].copy()\n",
    "display_image[mask_s] = 0\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "line = ax.imshow(display_image)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_low = slider_l.value\n",
    "threshold_high = slider_h.value\n",
    "\n",
    "masks = np.zeros(flow_recording.shape[:3],dtype=bool)\n",
    "\n",
    "for i in range(len(flow_recording)):\n",
    "    mask = get_mask_depth(depth[i], threshold_low, threshold_high)\n",
    "    mask = erode_mask(mask)\n",
    "    masks[i] = mask\n",
    "\n",
    "print(np.mean(masks) * 100, \"percent of pixels fg\")\n",
    "mask_fn = flow_recording_fn.replace(\".npz\",\"_mask.npz\")\n",
    "np.savez(mask_fn, mask=masks)\n",
    "print(\"Saved to\",mask_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "line = ax.imshow(masks[25])\n",
    "ax.set_axis_off()\n",
    "\n",
    "def update(i):\n",
    "    image = flow_recording[i].copy()\n",
    "    mask = masks[i]\n",
    "    image[mask] = 255,255,255\n",
    "    line.set_data(image)\n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "slider_i2 = widgets.IntSlider(min=0,max=num_frames,step=1,value=200,\n",
    "                             layout=Layout(width='70%'))\n",
    "\n",
    "interact(update, i=slider_i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
